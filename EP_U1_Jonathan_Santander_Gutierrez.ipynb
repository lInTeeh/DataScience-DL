{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_YDCi_7QayG"
      },
      "source": [
        "# Enunciado\n",
        "\n",
        "Construya una red neuronal con el objetivo de realizar la predicción sobre la data asociada a los precios de las propiedades de Boston."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxYNTa2hRSgw"
      },
      "source": [
        "# Fuente y descripción de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpsHjlMg_Mip"
      },
      "source": [
        "Este conjunto de datos se obtuvo del repositorio StatLib. https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
        "\n",
        "La variable objetivo es el valor medio de la vivienda para los distritos de California, expresado en cientos de miles de dólares ($100,000).\n",
        "\n",
        "Este conjunto de datos se derivó del censo de EE. UU. de 1990, utilizando una fila por grupo de bloques censales. Un grupo de bloque es la unidad geográfica más pequeña para la que la Oficina del Censo de EE. UU. publica datos de muestra (un grupo de bloque suele tener una población de 600 a 3000 personas).\n",
        "\n",
        "Un hogar es un grupo de personas que residen dentro de una casa. Dado que la cantidad promedio de habitaciones y dormitorios en este conjunto de datos se proporciona por hogar, estas columnas pueden tomar valores sorprendentemente grandes para grupos de bloques con pocos hogares y muchas casas vacías, como centros vacacionales.\n",
        "\n",
        "Características del conjunto de datos:\n",
        "\n",
        "Número de instancias \n",
        "20640\n",
        "\n",
        "Número de atributos \n",
        "8 atributos numéricos, predictivos y el objetivo\n",
        "\n",
        "Información de atributo \n",
        "* MedInc Ingreso promedio  \n",
        "\n",
        "* HouseAge edad promedio de la casa \n",
        "\n",
        "* AveRooms Número promedio de habitaciones por hogar\n",
        "\n",
        "* AveBedrms número promedio de dormitorios por hogar\n",
        "\n",
        "* Population Población \n",
        "\n",
        "* AveOccup número promedio de miembros del hogar\n",
        "\n",
        "* Latitude Latitud \n",
        "\n",
        "* Longitude Longitud \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y67F1MbVzDQO"
      },
      "source": [
        "Deberá abordar las etapas de la red\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDy0unDMzIOO"
      },
      "source": [
        "Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZV45MoPpSJ8j"
      },
      "outputs": [],
      "source": [
        "# Acá su código\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-AKYIROzSt4"
      },
      "source": [
        "Cargar datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HP4exVynzZCn"
      },
      "outputs": [],
      "source": [
        "#Acá su código\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "df_boston = fetch_california_housing(as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GnVw7Nfzbr8"
      },
      "source": [
        "Análisis de los datos : Explorar los datos con al menos 3 técnicas diferentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CCXn9lgpz3y9",
        "outputId": "6a2052f3-e576-4d9c-e13a-c508f86b78a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
              "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
              "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
              "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
              "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
              "\n",
              "   Longitude  MedHouseValue  \n",
              "0    -122.23          4.526  \n",
              "1    -122.22          3.585  \n",
              "2    -122.24          3.521  \n",
              "3    -122.25          3.413  \n",
              "4    -122.25          3.422  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0eef279d-7878-4364-b4b9-a78bc55ff327\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "      <td>4.526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "      <td>3.585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "      <td>3.521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "      <td>3.413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "      <td>3.422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0eef279d-7878-4364-b4b9-a78bc55ff327')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0eef279d-7878-4364-b4b9-a78bc55ff327 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0eef279d-7878-4364-b4b9-a78bc55ff327');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Acá su código\n",
        "df = pd.DataFrame(df_boston.data, columns= df_boston.feature_names)\n",
        "df['MedHouseValue'] = pd.Series(df_boston.target)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "717k485_ayaG",
        "outputId": "5b0936f5-62a3-4832-de09-42a012e5a603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
              "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
              "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
              "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
              "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
              "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
              "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
              "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
              "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
              "\n",
              "           AveOccup      Latitude     Longitude  MedHouseValue  \n",
              "count  20640.000000  20640.000000  20640.000000   20640.000000  \n",
              "mean       3.070655     35.631861   -119.569704       2.068558  \n",
              "std       10.386050      2.135952      2.003532       1.153956  \n",
              "min        0.692308     32.540000   -124.350000       0.149990  \n",
              "25%        2.429741     33.930000   -121.800000       1.196000  \n",
              "50%        2.818116     34.260000   -118.490000       1.797000  \n",
              "75%        3.282261     37.710000   -118.010000       2.647250  \n",
              "max     1243.333333     41.950000   -114.310000       5.000010  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e2f85b7-82bc-4fb8-90c9-7aa02ae07ebb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.870671</td>\n",
              "      <td>28.639486</td>\n",
              "      <td>5.429000</td>\n",
              "      <td>1.096675</td>\n",
              "      <td>1425.476744</td>\n",
              "      <td>3.070655</td>\n",
              "      <td>35.631861</td>\n",
              "      <td>-119.569704</td>\n",
              "      <td>2.068558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.899822</td>\n",
              "      <td>12.585558</td>\n",
              "      <td>2.474173</td>\n",
              "      <td>0.473911</td>\n",
              "      <td>1132.462122</td>\n",
              "      <td>10.386050</td>\n",
              "      <td>2.135952</td>\n",
              "      <td>2.003532</td>\n",
              "      <td>1.153956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.499900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>-124.350000</td>\n",
              "      <td>0.149990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.563400</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>4.440716</td>\n",
              "      <td>1.006079</td>\n",
              "      <td>787.000000</td>\n",
              "      <td>2.429741</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>-121.800000</td>\n",
              "      <td>1.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.534800</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.229129</td>\n",
              "      <td>1.048780</td>\n",
              "      <td>1166.000000</td>\n",
              "      <td>2.818116</td>\n",
              "      <td>34.260000</td>\n",
              "      <td>-118.490000</td>\n",
              "      <td>1.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.743250</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>6.052381</td>\n",
              "      <td>1.099526</td>\n",
              "      <td>1725.000000</td>\n",
              "      <td>3.282261</td>\n",
              "      <td>37.710000</td>\n",
              "      <td>-118.010000</td>\n",
              "      <td>2.647250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.000100</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>141.909091</td>\n",
              "      <td>34.066667</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>1243.333333</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>-114.310000</td>\n",
              "      <td>5.000010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e2f85b7-82bc-4fb8-90c9-7aa02ae07ebb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e2f85b7-82bc-4fb8-90c9-7aa02ae07ebb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e2f85b7-82bc-4fb8-90c9-7aa02ae07ebb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Realizamos la descripcion de los datos para ver los valores como el minimo y \n",
        "# el maximo de los datos que nos son relevantes como el valor promedio\n",
        "# de las casas \"MedInc\" (en cientos de miles de dolares).\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUCHw_4_twOS"
      },
      "source": [
        "Se muestran los datos estadisticos de cada columna, como el promedio, la moda, los valores minimos y maximos de cada una de las variables, los cuales nos ayudan a tener una nocion de si existiesen outliers o datos que se escapan de la realidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umkj0E9irNk1",
        "outputId": "e768fa21-dec2-4a3e-89c3-ba9caffa4640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
              "       'Latitude', 'Longitude', 'MedHouseValue'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Analizamos las columnas que contiene nuestro dataset para definir cuales ocuparemos\n",
        "# y cuales quedaran fuera del mismo.\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUCA2bdbrsi4"
      },
      "source": [
        "Identificamos 8 columnas, de las cuales a simple vista notamos que podemos sacar información de 6 de estas, quedando fuera la longitud la latitud ya que no nos entregan un valor que pueda definir el precio de las viviendas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DVlS_knrfiT",
        "outputId": "0b14f3ef-3708-4dc5-85f1-bd2a2dc14fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 9 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   MedInc         20640 non-null  float64\n",
            " 1   HouseAge       20640 non-null  float64\n",
            " 2   AveRooms       20640 non-null  float64\n",
            " 3   AveBedrms      20640 non-null  float64\n",
            " 4   Population     20640 non-null  float64\n",
            " 5   AveOccup       20640 non-null  float64\n",
            " 6   Latitude       20640 non-null  float64\n",
            " 7   Longitude      20640 non-null  float64\n",
            " 8   MedHouseValue  20640 non-null  float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 1.4 MB\n"
          ]
        }
      ],
      "source": [
        "# Analizamos los tipos de datos que tenemos y si existen nulls dentro\n",
        "# del dataset para ser eliminados o reemplazados por el promedio.\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgmGhhGZtpqu"
      },
      "source": [
        "Evidenciamos que todos los datos pertenecen a la categoria de float y no existen nulos dentro del dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0n1_yIGzvy9"
      },
      "source": [
        "Aplicar preprocesamiento a los datos : Al menos una técnica será necesaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6JWzvlzhz4-4"
      },
      "outputs": [],
      "source": [
        "# Multiplicamos por 100.000 las columnas \"Med Inc\" (Ingreso Promedio) y \n",
        "# de la variable \"MedHouseValue\" (Valor promedio de la casa) ya que estaban\n",
        "# medidas en cientos de miles de dolares y esto nos ayudará a un mejor analisis.\n",
        "# df['MedInc'] = df['MedInc']*100000\n",
        "# df['MedHouseValue'] = df['MedHouseValue']*100000\n",
        "# df\n",
        "\n",
        "# Disclaimer: al transformar las medidas de MedInc y MedHouseValue en cientos de\n",
        "# miles de dolares, el modelo se ve afectado negativamente, ya que el loss\n",
        "# nos arroja un valor inmenso (1777654433 aproximadamente) y un accuracy de 0\n",
        "# por lo cual se decidio omitir este procesamiento de los datos y dejar los\n",
        "# valores como venian por defecto en el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4v_UKIjx31DG"
      },
      "outputs": [],
      "source": [
        "#Eliminamos las columnas que no usaremos para realizar la prediccion.\n",
        "df = df.drop(['Latitude','Longitude'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1zUaMJp72NUs"
      },
      "outputs": [],
      "source": [
        "# Redondeamos los valores a datos enteros para tener una prediccion más precisa.\n",
        "# df = df.apply(np.ceil)\n",
        "# loss: 0.3607 - accuracy: 0.1776\n",
        "\n",
        "# Disclaimer : al usar el redondeo, el accuracy se ve afectado de forma negativa\n",
        "# el loss se ve afectado positivamente, pero igualmente sigue siendo un metodo\n",
        "# menos preciso que el que se muestra a continuacion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos a int los valores del DF\n",
        "df = df.astype(int)\n"
      ],
      "metadata": {
        "id": "r8adnJetFyyR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX7nE_ee_Ggt"
      },
      "source": [
        "Tratamiento de outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "DN12lV-8vmu9",
        "outputId": "3efc18dd-b9db-4b05-c3ce-f5fa4fdeeb9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Validamos la columna \"AveRooms\" en un grafico boxplot\n",
        "# para verificar la existencia de outliers.\n",
        "import seaborn as sns\n",
        "sns.boxplot(x = df['AveRooms'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6kZJM8_zsEL",
        "outputId": "71554909-527d-48d1-f4e4-9e144aa50d8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    20640.000000\n",
              "mean         4.933818\n",
              "std          2.489414\n",
              "min          0.000000\n",
              "25%          4.000000\n",
              "50%          5.000000\n",
              "75%          6.000000\n",
              "max        141.000000\n",
              "Name: AveRooms, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Realizamos la descripcion de la columna \"AveRooms\".\n",
        "df['AveRooms'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2oc13x5_NZ"
      },
      "source": [
        "Podemos evidenciar que existen datos atipicos o outliers como el dato \"142\" que nos indica que existe una cada que posee en promedio 142 habitaciones, por lo que procedemos a ver ese dato en especficico con el metodo \"loc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Rz9TZQ6Oer",
        "outputId": "f423403e-38f3-44f9-fa05-ad8d025b70cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
            "1914       1        33       141         25          30         2   \n",
            "\n",
            "      MedHouseValue  \n",
            "1914              5  \n"
          ]
        }
      ],
      "source": [
        "# Buscamos la fila que contiene el valor de \"AveRooms\" = 142\n",
        "print(df.loc[df['AveRooms']>140])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOJTzvSo60Fb"
      },
      "source": [
        "Evidenciamos que el dato arrojado arriba es atipico, ya que tenemos una casa con un valor de $500k con 142 habitaciones y 26 dormitorios, la cual es habitada solo por 3 personas, esto nos causa mucha rareza y puede ser un dato que haga que el modelo funcione de mala manera por lo cual será un dato que eliminaremos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa-h-Qga7dae"
      },
      "source": [
        "Para eliminar los valores atipicos o outliers usaremos la regla de Tukey o tambien conocido como IQR (Rango intercuartilico en español) que consiste en restar el Q3 - Q1 \n",
        "\n",
        "* Quedando la siguiente formula = (IQR = Q3 — Q1)\n",
        "\n",
        "* Obtendremos el limite inferior con la formula Q1–1.5 * IQR.\n",
        "\n",
        "* Obtendremos el limite superior con la formula Q3 + 1.5 * IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM6sasvV55YN",
        "outputId": "4d7ae557-88fa-481b-89af-7a7b7c26e90f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Detectamos el primer cuartil\n",
        "df['AveRooms'].quantile(.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoYRCu4q8ULh",
        "outputId": "08aec954-4c2a-4d6f-8a50-4575eabb6fb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Detectamos el tercer cuartil\n",
        "df['AveRooms'].quantile(.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3eOCR-738gEP"
      },
      "outputs": [],
      "source": [
        "# Almacenamos los cuartiles en sus respectivas variables\n",
        "# Q1 Y Q3 respectivamente y luego definimos la variable IQR para \n",
        "# realizar la formula antes descrita.\n",
        "Q1 = df['AveRooms'].quantile(.25)\n",
        "Q3 = df['AveRooms'].quantile(.75)\n",
        "IQR = Q3 - Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR9AbxNo8vE4",
        "outputId": "a1f37475-1f1b-41ab-e798-0d50625bcfdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Validamos el valor de IQR.\n",
        "IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6zcLseoI9L2m"
      },
      "outputs": [],
      "source": [
        "# Iniciamos las variables de limite inferior y limite superior\n",
        "# y definimos las formulas anteriormente descritas.\n",
        "lower_lim = Q1 - 1.5 * IQR\n",
        "upper_lim = Q3 + 1.5 * IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urctdzh299Ew",
        "outputId": "e0fd6750-345b-41a2-dc7c-b627225a2fee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Validamos el limite inferior.\n",
        "lower_lim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUQC-gs-R-C",
        "outputId": "75828c50-a5e4-4db6-8f91-a55298009e31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Validamos el limite superior.\n",
        "upper_lim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KbHnoUjK_nK8"
      },
      "outputs": [],
      "source": [
        "# A continuacion identificamos los outliers dentro de la columna \"AveRooms\"\n",
        "# y se guardan en sus respectivas variables (outliers low y up)\n",
        "outliers_low = (df['AveRooms'] < lower_lim)\n",
        "outliers_up = (df['AveRooms'] > upper_lim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qunLI0r2_-OQ",
        "outputId": "cde21242-d5c6-4638-e78a-13b63c164444"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20411"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Obtenemos la cantidad de datos sin valores atipicos.\n",
        "len(df['AveRooms']) - (len(df['AveRooms'][outliers_low]) + len(df['AveRooms'][outliers_up]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuFf1cPNAp8J",
        "outputId": "be033750-5591-4c92-a4cd-acb942fea4b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1023     10\n",
              "1024     29\n",
              "1030     10\n",
              "1102     31\n",
              "1233     16\n",
              "         ..\n",
              "20093    24\n",
              "20094    37\n",
              "20110    11\n",
              "20112    11\n",
              "20113    17\n",
              "Name: AveRooms, Length: 229, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Obtenemos los datos con valores atipicos.\n",
        "df['AveRooms'][(outliers_low | outliers_up)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M907QttQBenU",
        "outputId": "803e9ca4-4cca-40b6-a41b-09c1f22a1acf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        6\n",
              "1        6\n",
              "2        8\n",
              "3        5\n",
              "4        6\n",
              "        ..\n",
              "20635    5\n",
              "20636    6\n",
              "20637    5\n",
              "20638    5\n",
              "20639    5\n",
              "Name: AveRooms, Length: 20411, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Obtenemos los datos sin valores atipicos.\n",
        "df['AveRooms'][~(outliers_low | outliers_up)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SK_JikCvBuaY",
        "outputId": "aa3452ea-4b3f-4989-825e-60926a84ac0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
              "0           8        41         6          1         322         2   \n",
              "1           8        21         6          0        2401         2   \n",
              "2           7        52         8          1         496         2   \n",
              "3           5        52         5          1         558         2   \n",
              "4           3        52         6          1         565         2   \n",
              "...       ...       ...       ...        ...         ...       ...   \n",
              "20635       1        25         5          1         845         2   \n",
              "20636       2        18         6          1         356         3   \n",
              "20637       1        17         5          1        1007         2   \n",
              "20638       1        18         5          1         741         2   \n",
              "20639       2        16         5          1        1387         2   \n",
              "\n",
              "       MedHouseValue  \n",
              "0                  4  \n",
              "1                  3  \n",
              "2                  3  \n",
              "3                  3  \n",
              "4                  3  \n",
              "...              ...  \n",
              "20635              0  \n",
              "20636              0  \n",
              "20637              0  \n",
              "20638              0  \n",
              "20639              0  \n",
              "\n",
              "[20640 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70190d90-d3a5-4f0f-bba2-ce2ba26b0b10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>MedHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2401</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>52</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>496</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>52</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>558</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>565</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>845</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>356</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1007</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>741</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1387</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70190d90-d3a5-4f0f-bba2-ce2ba26b0b10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70190d90-d3a5-4f0f-bba2-ce2ba26b0b10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70190d90-d3a5-4f0f-bba2-ce2ba26b0b10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Obtenemos nuestro df con los datos atipicos aun en el.\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wQ5H6wnTB4Qn",
        "outputId": "a097e215-e21c-41b1-aead-906f22ef3bc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
              "0           8        41         6          1         322         2   \n",
              "1           8        21         6          0        2401         2   \n",
              "2           7        52         8          1         496         2   \n",
              "3           5        52         5          1         558         2   \n",
              "4           3        52         6          1         565         2   \n",
              "...       ...       ...       ...        ...         ...       ...   \n",
              "20635       1        25         5          1         845         2   \n",
              "20636       2        18         6          1         356         3   \n",
              "20637       1        17         5          1        1007         2   \n",
              "20638       1        18         5          1         741         2   \n",
              "20639       2        16         5          1        1387         2   \n",
              "\n",
              "       MedHouseValue  \n",
              "0                  4  \n",
              "1                  3  \n",
              "2                  3  \n",
              "3                  3  \n",
              "4                  3  \n",
              "...              ...  \n",
              "20635              0  \n",
              "20636              0  \n",
              "20637              0  \n",
              "20638              0  \n",
              "20639              0  \n",
              "\n",
              "[20638 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33ce16e3-664d-4745-9118-eaaea5b88297\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>MedHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2401</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>52</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>496</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>52</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>558</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>565</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>845</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>356</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1007</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>741</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1387</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20638 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ce16e3-664d-4745-9118-eaaea5b88297')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33ce16e3-664d-4745-9118-eaaea5b88297 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33ce16e3-664d-4745-9118-eaaea5b88297');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Almacenamos nuestro dataset sin datos atipicos.\n",
        "df = df[~(outliers_low) | (outliers_up)]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "40iD2Sy3EUhV",
        "outputId": "79b85238-d3ac-4af4-c558-f28c28cdf825"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Validamos que se haya realizado la eliminación de valores atipicos\n",
        "sns.boxplot(x = df['AveRooms'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf9uj5yhzqOt"
      },
      "source": [
        "Separar datos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZyCMFO8z5qh",
        "outputId": "c0849954-b107-4ff9-add6-9d46b88c4bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (16510, 6)\n",
            "X_test shape:  (4128, 6)\n",
            "y_train shape:  (16510,)\n",
            "y_test shape:  (4128,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "#Separar la columna objetivo del dataset\n",
        "X = df.drop(['MedHouseValue'],1)\n",
        "y = df['MedHouseValue']\n",
        "\n",
        "#Ahora viene separar los datos entre entrenamiento y prueba, usando los 4 conjuntos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#test_split = 0.2 significa que se separan 80:20 y random_state solo es para darle una semilla\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4)\n",
        "\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cgwFFjFvbACR",
        "outputId": "d9d46ab5-d8c5-43c6-8b1a-8d342baa4503"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup\n",
              "4519        1        44         3          1        1998         3\n",
              "29          1        52         4          1         395         2\n",
              "7339        2        23         3          1        1977         4\n",
              "1067        3        52         4          0        1107        11\n",
              "5082        2        44         4          0         811         2\n",
              "...       ...       ...       ...        ...         ...       ...\n",
              "16842       5        28         6          1        2683         3\n",
              "11865       5        10        15          2         247         2\n",
              "17095       3        36         4          1        1117         2\n",
              "8368        3        42         5          1        1785         2\n",
              "17532       0        20         2          1         851         1\n",
              "\n",
              "[16510 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e02b76ce-6697-4d2d-be3b-1b02fc31259e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4519</th>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1998</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>395</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7339</th>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1977</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1107</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5082</th>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>811</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16842</th>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2683</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11865</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>247</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17095</th>\n",
              "      <td>3</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1117</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8368</th>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1785</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17532</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>851</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16510 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e02b76ce-6697-4d2d-be3b-1b02fc31259e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e02b76ce-6697-4d2d-be3b-1b02fc31259e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e02b76ce-6697-4d2d-be3b-1b02fc31259e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Validamos los datos separados \"X\".\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixQbraxKbACS",
        "outputId": "126065c2-89da-4f6e-8067-097ba2a68791"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4519     1\n",
              "29       1\n",
              "7339     1\n",
              "1067     1\n",
              "5082     0\n",
              "        ..\n",
              "16842    3\n",
              "11865    1\n",
              "17095    3\n",
              "8368     1\n",
              "17532    3\n",
              "Name: MedHouseValue, Length: 16510, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Validamos los datos de \"Y\"\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos la normalización de los datos \"X\" ya separados.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "MinMax = MinMaxScaler().fit(X_train)\n",
        "X_train_n = MinMax.transform(X_train)\n",
        "X_test_n = MinMax.transform(X_test)"
      ],
      "metadata": {
        "id": "IXCi-r7i48Oe"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": false,
        "id": "pW5iylaubACS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98c4a93-e25b-4a69-c663-3ded63bdbe94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.66666667e-02, 8.43137255e-01, 1.52671756e-02, 2.94117647e-02,\n",
              "        5.59152443e-02, 2.41351569e-03],\n",
              "       [6.66666667e-02, 1.00000000e+00, 2.29007634e-02, 2.94117647e-02,\n",
              "        1.09868550e-02, 1.60901046e-03],\n",
              "       [1.33333333e-01, 4.31372549e-01, 1.52671756e-02, 2.94117647e-02,\n",
              "        5.53266627e-02, 3.21802092e-03],\n",
              "       ...,\n",
              "       [2.00000000e-01, 6.86274510e-01, 2.29007634e-02, 2.94117647e-02,\n",
              "        3.12228482e-02, 1.60901046e-03],\n",
              "       [2.00000000e-01, 8.03921569e-01, 3.05343511e-02, 2.94117647e-02,\n",
              "        4.99453460e-02, 1.60901046e-03],\n",
              "       [0.00000000e+00, 3.72549020e-01, 7.63358779e-03, 2.94117647e-02,\n",
              "        2.37674823e-02, 8.04505229e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Validamos los datos de entrenamiento \"X\" normalizados.\n",
        "X_train_n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos los datos de prueba \"X\" normalizados\n",
        "X_test_n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzlyz2JW7Gyp",
        "outputId": "e9b20e60-2af3-4017-b627-65ae994a80fb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.26666667, 0.1372549 , 0.03053435, 0.        , 0.01241627,\n",
              "        0.00241352],\n",
              "       [0.13333333, 0.19607843, 0.        , 0.02941176, 0.03195157,\n",
              "        0.00241352],\n",
              "       [0.13333333, 0.49019608, 0.02290076, 0.02941176, 0.07107823,\n",
              "        0.00160901],\n",
              "       ...,\n",
              "       [0.13333333, 0.82352941, 0.02290076, 0.02941176, 0.03377337,\n",
              "        0.00160901],\n",
              "       [0.26666667, 0.43137255, 0.02290076, 0.02941176, 0.07971075,\n",
              "        0.00160901],\n",
              "       [0.13333333, 0.43137255, 0.03053435, 0.        , 0.01014602,\n",
              "        0.00160901]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estandarizamos los datos \"X\"\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler().fit(X_train)\n",
        "X_train_s = scale.transform(X_train)\n",
        "X_test_s = scale.transform(X_test)"
      ],
      "metadata": {
        "id": "RdJFJEnx8Nh7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos los datos de entrenamiento \"X\" Estandarizados.\n",
        "X_train_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18rruYHE8YoT",
        "outputId": "076b5f58-aacf-47e6-c87c-06575b772843"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.2329574 ,  1.21733818, -0.81074482,  0.30684898,  0.5035273 ,\n",
              "         0.03940337],\n",
              "       [-1.2329574 ,  1.85207081, -0.39056034,  0.30684898, -0.90910612,\n",
              "        -0.05205588],\n",
              "       [-0.71782108, -0.44883497, -0.81074482,  0.30684898,  0.48502119,\n",
              "         0.13086262],\n",
              "       ...,\n",
              "       [-0.20268477,  0.58260555, -0.39056034,  0.30684898, -0.27284827,\n",
              "        -0.05205588],\n",
              "       [-0.20268477,  1.05865502,  0.02962415,  0.30684898,  0.31582243,\n",
              "        -0.05205588],\n",
              "       [-1.74809371, -0.68685971, -1.23092931,  0.30684898, -0.50725906,\n",
              "        -0.14351513]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos los datos de prueba \"X\" Estandarizados.\n",
        "X_test_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKBBZkV58XGT",
        "outputId": "80ad6a4b-9d02-4d6d-c87c-30fde7b90894"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.31245155, -1.63895865,  0.02962415, -1.34981443, -0.8641627 ,\n",
              "         0.03940337],\n",
              "       [-0.71782108, -1.40093392, -1.6511138 ,  0.30684898, -0.24993594,\n",
              "         0.03940337],\n",
              "       [-0.71782108, -0.21081024, -0.39056034,  0.30684898,  0.98028007,\n",
              "        -0.05205588],\n",
              "       ...,\n",
              "       [-0.71782108,  1.1379966 , -0.39056034,  0.30684898, -0.19265511,\n",
              "        -0.05205588],\n",
              "       [ 0.31245155, -0.44883497, -0.39056034,  0.30684898,  1.25170309,\n",
              "        -0.05205588],\n",
              "       [-0.71782108, -0.44883497,  0.02962415, -1.34981443, -0.93554343,\n",
              "        -0.05205588]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZU8sr59k4Yc",
        "outputId": "d4666fc2-566b-40db-aaec-0cec8fa126cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20638, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Identificamos las dimensiones de nuestro dataset.\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emOFBv3VzmEN"
      },
      "source": [
        "Crear la arquitectura de la red: proponga la cantidad de neuronas y capas ocultas que estime conveniente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8vh_2hlz7Ev",
        "outputId": "d0eaa8e4-78ae-49fd-9d64-9dd332af80be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_input (Dense)          (None, 512)               3584      \n",
            "                                                                 \n",
            " Capa_oculta_1 (Dense)       (None, 512)               262656    \n",
            "                                                                 \n",
            " Capa_oculta_2 (Dense)       (None, 256)               131328    \n",
            "                                                                 \n",
            " Capa_oculta_3 (Dense)       (None, 256)               65792     \n",
            "                                                                 \n",
            " Capa_oculta_4 (Dense)       (None, 128)               32896     \n",
            "                                                                 \n",
            " Capa_output (Dense)         (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 496,385\n",
            "Trainable params: 496,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Creamos la arquitectura de la red.\n",
        "red = keras.Sequential()\n",
        "\n",
        "red.add(\n",
        "    keras.layers.Dense(512, input_dim=6, name=\"Capa_input\")\n",
        ")\n",
        "\n",
        "red.add(\n",
        "    keras.layers.Dense(512, activation = 'relu', name = \"Capa_oculta_1\")\n",
        ")\n",
        "\n",
        "red.add(\n",
        "    keras.layers.Dense(256, activation = 'relu', name = \"Capa_oculta_2\")\n",
        ")\n",
        "\n",
        "red.add(\n",
        "    keras.layers.Dense(256, activation = 'relu', name = \"Capa_oculta_3\")\n",
        ")\n",
        "\n",
        "red.add(\n",
        "    keras.layers.Dense(128, activation = 'relu', name = \"Capa_oculta_4\")\n",
        ")\n",
        "\n",
        "red.add(\n",
        "    keras.layers.Dense(1, activation = 'relu', name= \"Capa_output\")\n",
        ")\n",
        "\n",
        "# Disclaimer : en un principio teniamos 4 capas, 1 de input 2 ocultas y\n",
        "# 1 de output, lo cual nos arrojaba un accuracy muy bajo y un loss muy\n",
        "# alto por lo cual se decidio cambiar la arquitectura de la red a una red\n",
        "# de 6 capas, 4 ocultas, 1 de input y 1 de output, todas con activacion\n",
        "# relu, mejorando asi el loss y accuracy de nuestro modelo.\n",
        "red.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAJ-g44L0DGF"
      },
      "source": [
        "Defina el modelo de compilación, considerando los hiperparámetros pertinentes al estudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8sRv-n-E0J0g"
      },
      "outputs": [],
      "source": [
        "#Acá su código\n",
        "red.compile(loss='mse', optimizer='adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH9xsO-t0Q1_"
      },
      "source": [
        "Entrene el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d5x4m_D0Tq2",
        "outputId": "18ab2bf3-d0ab-40b6-8c25-7da663f75e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3315 - accuracy: 0.4967 - val_loss: 0.8266 - val_accuracy: 0.4191\n",
            "Epoch 2/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3272 - accuracy: 0.4969 - val_loss: 0.8089 - val_accuracy: 0.4264\n",
            "Epoch 3/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3377 - accuracy: 0.4952 - val_loss: 0.8069 - val_accuracy: 0.4251\n",
            "Epoch 4/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3277 - accuracy: 0.4971 - val_loss: 0.7871 - val_accuracy: 0.4276\n",
            "Epoch 5/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3341 - accuracy: 0.4979 - val_loss: 0.8261 - val_accuracy: 0.4254\n",
            "Epoch 6/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3464 - accuracy: 0.4960 - val_loss: 0.8007 - val_accuracy: 0.4327\n",
            "Epoch 7/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3430 - accuracy: 0.4944 - val_loss: 0.8297 - val_accuracy: 0.4264\n",
            "Epoch 8/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3429 - accuracy: 0.4947 - val_loss: 0.8281 - val_accuracy: 0.4239\n",
            "Epoch 9/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.5986 - accuracy: 0.4486 - val_loss: 0.7235 - val_accuracy: 0.4215\n",
            "Epoch 10/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.4364 - accuracy: 0.4724 - val_loss: 0.7681 - val_accuracy: 0.4244\n",
            "Epoch 11/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3968 - accuracy: 0.4828 - val_loss: 0.8293 - val_accuracy: 0.4264\n",
            "Epoch 12/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3753 - accuracy: 0.4855 - val_loss: 0.7948 - val_accuracy: 0.4234\n",
            "Epoch 13/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3380 - accuracy: 0.4944 - val_loss: 0.8126 - val_accuracy: 0.4227\n",
            "Epoch 14/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3242 - accuracy: 0.4984 - val_loss: 0.8232 - val_accuracy: 0.4237\n",
            "Epoch 15/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3845 - accuracy: 0.4875 - val_loss: 0.7969 - val_accuracy: 0.4276\n",
            "Epoch 16/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3310 - accuracy: 0.4974 - val_loss: 0.7999 - val_accuracy: 0.4285\n",
            "Epoch 17/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3363 - accuracy: 0.4944 - val_loss: 0.8112 - val_accuracy: 0.4251\n",
            "Epoch 18/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3339 - accuracy: 0.4969 - val_loss: 0.8831 - val_accuracy: 0.4237\n",
            "Epoch 19/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.4381 - accuracy: 0.4794 - val_loss: 0.7889 - val_accuracy: 0.4237\n",
            "Epoch 20/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3411 - accuracy: 0.4953 - val_loss: 0.8181 - val_accuracy: 0.4220\n",
            "Epoch 21/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3316 - accuracy: 0.4973 - val_loss: 0.8061 - val_accuracy: 0.4232\n",
            "Epoch 22/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3318 - accuracy: 0.4964 - val_loss: 0.8114 - val_accuracy: 0.4256\n",
            "Epoch 23/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3280 - accuracy: 0.4995 - val_loss: 0.7855 - val_accuracy: 0.4290\n",
            "Epoch 24/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3437 - accuracy: 0.4949 - val_loss: 0.8054 - val_accuracy: 0.4271\n",
            "Epoch 25/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3360 - accuracy: 0.4981 - val_loss: 0.7943 - val_accuracy: 0.4237\n",
            "Epoch 26/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3257 - accuracy: 0.4995 - val_loss: 0.8019 - val_accuracy: 0.4208\n",
            "Epoch 27/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3637 - accuracy: 0.4931 - val_loss: 0.8010 - val_accuracy: 0.4290\n",
            "Epoch 28/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3535 - accuracy: 0.4914 - val_loss: 0.8093 - val_accuracy: 0.4247\n",
            "Epoch 29/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3276 - accuracy: 0.4959 - val_loss: 0.8209 - val_accuracy: 0.4273\n",
            "Epoch 30/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3198 - accuracy: 0.5000 - val_loss: 0.8293 - val_accuracy: 0.4244\n",
            "Epoch 31/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3198 - accuracy: 0.4987 - val_loss: 0.8019 - val_accuracy: 0.4230\n",
            "Epoch 32/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.4249 - accuracy: 0.4818 - val_loss: 0.7984 - val_accuracy: 0.4254\n",
            "Epoch 33/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3487 - accuracy: 0.4918 - val_loss: 0.8011 - val_accuracy: 0.4261\n",
            "Epoch 34/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3540 - accuracy: 0.4915 - val_loss: 0.8092 - val_accuracy: 0.4259\n",
            "Epoch 35/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3504 - accuracy: 0.4924 - val_loss: 0.8077 - val_accuracy: 0.4232\n",
            "Epoch 36/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3271 - accuracy: 0.4981 - val_loss: 0.8113 - val_accuracy: 0.4218\n",
            "Epoch 37/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3218 - accuracy: 0.4993 - val_loss: 0.8160 - val_accuracy: 0.4220\n",
            "Epoch 38/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3130 - accuracy: 0.5029 - val_loss: 0.8079 - val_accuracy: 0.4218\n",
            "Epoch 39/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3208 - accuracy: 0.5017 - val_loss: 0.8079 - val_accuracy: 0.4261\n",
            "Epoch 40/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3094 - accuracy: 0.5031 - val_loss: 0.8117 - val_accuracy: 0.4249\n",
            "Epoch 41/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3115 - accuracy: 0.5015 - val_loss: 0.8186 - val_accuracy: 0.4186\n",
            "Epoch 42/511\n",
            "67/67 [==============================] - 2s 33ms/step - loss: 0.3047 - accuracy: 0.5040 - val_loss: 0.8689 - val_accuracy: 0.4230\n",
            "Epoch 43/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3867 - accuracy: 0.4882 - val_loss: 0.8086 - val_accuracy: 0.4247\n",
            "Epoch 44/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3373 - accuracy: 0.4955 - val_loss: 0.7998 - val_accuracy: 0.4222\n",
            "Epoch 45/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3227 - accuracy: 0.5018 - val_loss: 0.8239 - val_accuracy: 0.4244\n",
            "Epoch 46/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3131 - accuracy: 0.5027 - val_loss: 0.8278 - val_accuracy: 0.4261\n",
            "Epoch 47/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3223 - accuracy: 0.4995 - val_loss: 0.8204 - val_accuracy: 0.4237\n",
            "Epoch 48/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3392 - accuracy: 0.4970 - val_loss: 0.8424 - val_accuracy: 0.4251\n",
            "Epoch 49/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3248 - accuracy: 0.4988 - val_loss: 0.8296 - val_accuracy: 0.4232\n",
            "Epoch 50/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3228 - accuracy: 0.5014 - val_loss: 0.8065 - val_accuracy: 0.4288\n",
            "Epoch 51/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3144 - accuracy: 0.5010 - val_loss: 0.8321 - val_accuracy: 0.4242\n",
            "Epoch 52/511\n",
            "67/67 [==============================] - 3s 41ms/step - loss: 0.3116 - accuracy: 0.5044 - val_loss: 0.8371 - val_accuracy: 0.4220\n",
            "Epoch 53/511\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 0.3108 - accuracy: 0.5018 - val_loss: 0.8224 - val_accuracy: 0.4237\n",
            "Epoch 54/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3125 - accuracy: 0.4998 - val_loss: 0.8257 - val_accuracy: 0.4230\n",
            "Epoch 55/511\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 0.3125 - accuracy: 0.5031 - val_loss: 0.8354 - val_accuracy: 0.4225\n",
            "Epoch 56/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3141 - accuracy: 0.5031 - val_loss: 0.8539 - val_accuracy: 0.4242\n",
            "Epoch 57/511\n",
            "67/67 [==============================] - 3s 43ms/step - loss: 0.3190 - accuracy: 0.5002 - val_loss: 0.8411 - val_accuracy: 0.4234\n",
            "Epoch 58/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3201 - accuracy: 0.4971 - val_loss: 0.8250 - val_accuracy: 0.4208\n",
            "Epoch 59/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3212 - accuracy: 0.4992 - val_loss: 0.8181 - val_accuracy: 0.4227\n",
            "Epoch 60/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3071 - accuracy: 0.5030 - val_loss: 0.8389 - val_accuracy: 0.4264\n",
            "Epoch 61/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3149 - accuracy: 0.5014 - val_loss: 0.8483 - val_accuracy: 0.4264\n",
            "Epoch 62/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3258 - accuracy: 0.5008 - val_loss: 0.8407 - val_accuracy: 0.4203\n",
            "Epoch 63/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3061 - accuracy: 0.5036 - val_loss: 0.8414 - val_accuracy: 0.4232\n",
            "Epoch 64/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2998 - accuracy: 0.5048 - val_loss: 0.8374 - val_accuracy: 0.4278\n",
            "Epoch 65/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3237 - accuracy: 0.5007 - val_loss: 0.8282 - val_accuracy: 0.4198\n",
            "Epoch 66/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3094 - accuracy: 0.5039 - val_loss: 0.8433 - val_accuracy: 0.4244\n",
            "Epoch 67/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3295 - accuracy: 0.4963 - val_loss: 0.8111 - val_accuracy: 0.4230\n",
            "Epoch 68/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3295 - accuracy: 0.4984 - val_loss: 0.8259 - val_accuracy: 0.4249\n",
            "Epoch 69/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3122 - accuracy: 0.5028 - val_loss: 0.8698 - val_accuracy: 0.4285\n",
            "Epoch 70/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3227 - accuracy: 0.5026 - val_loss: 0.8383 - val_accuracy: 0.4230\n",
            "Epoch 71/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3128 - accuracy: 0.5006 - val_loss: 0.8021 - val_accuracy: 0.4222\n",
            "Epoch 72/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3079 - accuracy: 0.5041 - val_loss: 0.8431 - val_accuracy: 0.4234\n",
            "Epoch 73/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3340 - accuracy: 0.4972 - val_loss: 0.8353 - val_accuracy: 0.4302\n",
            "Epoch 74/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3029 - accuracy: 0.5026 - val_loss: 0.8447 - val_accuracy: 0.4247\n",
            "Epoch 75/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3009 - accuracy: 0.5058 - val_loss: 0.8447 - val_accuracy: 0.4232\n",
            "Epoch 76/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3147 - accuracy: 0.5022 - val_loss: 0.8225 - val_accuracy: 0.4237\n",
            "Epoch 77/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3099 - accuracy: 0.5025 - val_loss: 0.8098 - val_accuracy: 0.4201\n",
            "Epoch 78/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3148 - accuracy: 0.5012 - val_loss: 0.8234 - val_accuracy: 0.4169\n",
            "Epoch 79/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3058 - accuracy: 0.5042 - val_loss: 0.8342 - val_accuracy: 0.4244\n",
            "Epoch 80/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2959 - accuracy: 0.5071 - val_loss: 0.8220 - val_accuracy: 0.4271\n",
            "Epoch 81/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3124 - accuracy: 0.5024 - val_loss: 0.8566 - val_accuracy: 0.4261\n",
            "Epoch 82/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3069 - accuracy: 0.5050 - val_loss: 0.9503 - val_accuracy: 0.4167\n",
            "Epoch 83/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3582 - accuracy: 0.4935 - val_loss: 0.8347 - val_accuracy: 0.4239\n",
            "Epoch 84/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3100 - accuracy: 0.5034 - val_loss: 0.8399 - val_accuracy: 0.4220\n",
            "Epoch 85/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2960 - accuracy: 0.5066 - val_loss: 0.8457 - val_accuracy: 0.4268\n",
            "Epoch 86/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3200 - accuracy: 0.4992 - val_loss: 0.8562 - val_accuracy: 0.4205\n",
            "Epoch 87/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3056 - accuracy: 0.5052 - val_loss: 0.8198 - val_accuracy: 0.4196\n",
            "Epoch 88/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3062 - accuracy: 0.5058 - val_loss: 0.8521 - val_accuracy: 0.4234\n",
            "Epoch 89/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3159 - accuracy: 0.5030 - val_loss: 0.8248 - val_accuracy: 0.4218\n",
            "Epoch 90/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2959 - accuracy: 0.5061 - val_loss: 0.8371 - val_accuracy: 0.4193\n",
            "Epoch 91/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3575 - accuracy: 0.4916 - val_loss: 0.8287 - val_accuracy: 0.4232\n",
            "Epoch 92/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3026 - accuracy: 0.5055 - val_loss: 0.8394 - val_accuracy: 0.4215\n",
            "Epoch 93/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3074 - accuracy: 0.5023 - val_loss: 0.8459 - val_accuracy: 0.4210\n",
            "Epoch 94/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2996 - accuracy: 0.5063 - val_loss: 0.8552 - val_accuracy: 0.4213\n",
            "Epoch 95/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2962 - accuracy: 0.5079 - val_loss: 0.8380 - val_accuracy: 0.4232\n",
            "Epoch 96/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2929 - accuracy: 0.5083 - val_loss: 0.8281 - val_accuracy: 0.4237\n",
            "Epoch 97/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3190 - accuracy: 0.5023 - val_loss: 0.8874 - val_accuracy: 0.4247\n",
            "Epoch 98/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3555 - accuracy: 0.5001 - val_loss: 0.8342 - val_accuracy: 0.4232\n",
            "Epoch 99/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3076 - accuracy: 0.5060 - val_loss: 0.8047 - val_accuracy: 0.4244\n",
            "Epoch 100/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3014 - accuracy: 0.5076 - val_loss: 0.8425 - val_accuracy: 0.4281\n",
            "Epoch 101/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3024 - accuracy: 0.5051 - val_loss: 0.8332 - val_accuracy: 0.4208\n",
            "Epoch 102/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3281 - accuracy: 0.4995 - val_loss: 0.8257 - val_accuracy: 0.4249\n",
            "Epoch 103/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3077 - accuracy: 0.5037 - val_loss: 0.8301 - val_accuracy: 0.4213\n",
            "Epoch 104/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2983 - accuracy: 0.5067 - val_loss: 0.8409 - val_accuracy: 0.4239\n",
            "Epoch 105/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2911 - accuracy: 0.5075 - val_loss: 0.8290 - val_accuracy: 0.4191\n",
            "Epoch 106/511\n",
            "67/67 [==============================] - 3s 49ms/step - loss: 0.3019 - accuracy: 0.5064 - val_loss: 0.9359 - val_accuracy: 0.4256\n",
            "Epoch 107/511\n",
            "67/67 [==============================] - 3s 51ms/step - loss: 0.6897 - accuracy: 0.4380 - val_loss: 0.6647 - val_accuracy: 0.4203\n",
            "Epoch 108/511\n",
            "67/67 [==============================] - 2s 34ms/step - loss: 0.5863 - accuracy: 0.4449 - val_loss: 0.6829 - val_accuracy: 0.4256\n",
            "Epoch 109/511\n",
            "67/67 [==============================] - 3s 43ms/step - loss: 0.5218 - accuracy: 0.4489 - val_loss: 0.7061 - val_accuracy: 0.4288\n",
            "Epoch 110/511\n",
            "67/67 [==============================] - 3s 51ms/step - loss: 0.4432 - accuracy: 0.4649 - val_loss: 0.8047 - val_accuracy: 0.4271\n",
            "Epoch 111/511\n",
            "67/67 [==============================] - 3s 51ms/step - loss: 0.3800 - accuracy: 0.4830 - val_loss: 0.8139 - val_accuracy: 0.4237\n",
            "Epoch 112/511\n",
            "67/67 [==============================] - 4s 52ms/step - loss: 0.3321 - accuracy: 0.4946 - val_loss: 0.8149 - val_accuracy: 0.4244\n",
            "Epoch 113/511\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 0.3255 - accuracy: 0.4993 - val_loss: 0.8223 - val_accuracy: 0.4242\n",
            "Epoch 114/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3044 - accuracy: 0.5023 - val_loss: 0.8346 - val_accuracy: 0.4249\n",
            "Epoch 115/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2937 - accuracy: 0.5039 - val_loss: 0.8263 - val_accuracy: 0.4281\n",
            "Epoch 116/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2983 - accuracy: 0.5058 - val_loss: 0.8392 - val_accuracy: 0.4230\n",
            "Epoch 117/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3368 - accuracy: 0.4964 - val_loss: 0.8782 - val_accuracy: 0.4232\n",
            "Epoch 118/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3224 - accuracy: 0.5005 - val_loss: 0.8142 - val_accuracy: 0.4220\n",
            "Epoch 119/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3131 - accuracy: 0.5031 - val_loss: 0.8712 - val_accuracy: 0.4237\n",
            "Epoch 120/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3023 - accuracy: 0.5064 - val_loss: 0.8216 - val_accuracy: 0.4193\n",
            "Epoch 121/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3044 - accuracy: 0.5025 - val_loss: 0.8473 - val_accuracy: 0.4186\n",
            "Epoch 122/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2908 - accuracy: 0.5084 - val_loss: 0.8238 - val_accuracy: 0.4191\n",
            "Epoch 123/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2923 - accuracy: 0.5071 - val_loss: 0.7758 - val_accuracy: 0.4283\n",
            "Epoch 124/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.4663 - accuracy: 0.4683 - val_loss: 0.8005 - val_accuracy: 0.4254\n",
            "Epoch 125/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3318 - accuracy: 0.4921 - val_loss: 0.8393 - val_accuracy: 0.4225\n",
            "Epoch 126/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3013 - accuracy: 0.5020 - val_loss: 0.8415 - val_accuracy: 0.4208\n",
            "Epoch 127/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3131 - accuracy: 0.5035 - val_loss: 0.8413 - val_accuracy: 0.4249\n",
            "Epoch 128/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2900 - accuracy: 0.5091 - val_loss: 0.8244 - val_accuracy: 0.4259\n",
            "Epoch 129/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2889 - accuracy: 0.5063 - val_loss: 0.8412 - val_accuracy: 0.4249\n",
            "Epoch 130/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2869 - accuracy: 0.5089 - val_loss: 0.8498 - val_accuracy: 0.4237\n",
            "Epoch 131/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2825 - accuracy: 0.5101 - val_loss: 0.8320 - val_accuracy: 0.4234\n",
            "Epoch 132/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2865 - accuracy: 0.5090 - val_loss: 0.8371 - val_accuracy: 0.4232\n",
            "Epoch 133/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2897 - accuracy: 0.5036 - val_loss: 0.8460 - val_accuracy: 0.4227\n",
            "Epoch 134/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2818 - accuracy: 0.5091 - val_loss: 0.8724 - val_accuracy: 0.4215\n",
            "Epoch 135/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2957 - accuracy: 0.5070 - val_loss: 0.8641 - val_accuracy: 0.4196\n",
            "Epoch 136/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2859 - accuracy: 0.5098 - val_loss: 0.8550 - val_accuracy: 0.4249\n",
            "Epoch 137/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3347 - accuracy: 0.4998 - val_loss: 0.8718 - val_accuracy: 0.4239\n",
            "Epoch 138/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3257 - accuracy: 0.5036 - val_loss: 0.8508 - val_accuracy: 0.4234\n",
            "Epoch 139/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2845 - accuracy: 0.5095 - val_loss: 0.8462 - val_accuracy: 0.4225\n",
            "Epoch 140/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2817 - accuracy: 0.5090 - val_loss: 0.8582 - val_accuracy: 0.4222\n",
            "Epoch 141/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2827 - accuracy: 0.5087 - val_loss: 0.8429 - val_accuracy: 0.4256\n",
            "Epoch 142/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3136 - accuracy: 0.5030 - val_loss: 0.8295 - val_accuracy: 0.4188\n",
            "Epoch 143/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3577 - accuracy: 0.4906 - val_loss: 0.8209 - val_accuracy: 0.4205\n",
            "Epoch 144/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3115 - accuracy: 0.5024 - val_loss: 0.8784 - val_accuracy: 0.4254\n",
            "Epoch 145/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3064 - accuracy: 0.5064 - val_loss: 0.8617 - val_accuracy: 0.4227\n",
            "Epoch 146/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3029 - accuracy: 0.5062 - val_loss: 0.8587 - val_accuracy: 0.4215\n",
            "Epoch 147/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2856 - accuracy: 0.5094 - val_loss: 0.8698 - val_accuracy: 0.4230\n",
            "Epoch 148/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2844 - accuracy: 0.5113 - val_loss: 0.8707 - val_accuracy: 0.4191\n",
            "Epoch 149/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3065 - accuracy: 0.4982 - val_loss: 0.8798 - val_accuracy: 0.4230\n",
            "Epoch 150/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2831 - accuracy: 0.5074 - val_loss: 0.8571 - val_accuracy: 0.4203\n",
            "Epoch 151/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2849 - accuracy: 0.5079 - val_loss: 0.8641 - val_accuracy: 0.4213\n",
            "Epoch 152/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2974 - accuracy: 0.5028 - val_loss: 0.8612 - val_accuracy: 0.4203\n",
            "Epoch 153/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2820 - accuracy: 0.5098 - val_loss: 0.8712 - val_accuracy: 0.4159\n",
            "Epoch 154/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3202 - accuracy: 0.5036 - val_loss: 0.8445 - val_accuracy: 0.4191\n",
            "Epoch 155/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2899 - accuracy: 0.5092 - val_loss: 0.8376 - val_accuracy: 0.4230\n",
            "Epoch 156/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3035 - accuracy: 0.5074 - val_loss: 0.8539 - val_accuracy: 0.4218\n",
            "Epoch 157/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2892 - accuracy: 0.5094 - val_loss: 0.8591 - val_accuracy: 0.4266\n",
            "Epoch 158/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2877 - accuracy: 0.5072 - val_loss: 0.8493 - val_accuracy: 0.4259\n",
            "Epoch 159/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3072 - accuracy: 0.5067 - val_loss: 0.8734 - val_accuracy: 0.4181\n",
            "Epoch 160/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2890 - accuracy: 0.5095 - val_loss: 0.8569 - val_accuracy: 0.4244\n",
            "Epoch 161/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2810 - accuracy: 0.5090 - val_loss: 0.8363 - val_accuracy: 0.4210\n",
            "Epoch 162/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2794 - accuracy: 0.5102 - val_loss: 0.8690 - val_accuracy: 0.4213\n",
            "Epoch 163/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2675 - accuracy: 0.5121 - val_loss: 0.8633 - val_accuracy: 0.4188\n",
            "Epoch 164/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3149 - accuracy: 0.5042 - val_loss: 0.8967 - val_accuracy: 0.4225\n",
            "Epoch 165/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3348 - accuracy: 0.4976 - val_loss: 0.8689 - val_accuracy: 0.4264\n",
            "Epoch 166/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2888 - accuracy: 0.5061 - val_loss: 0.8721 - val_accuracy: 0.4201\n",
            "Epoch 167/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2707 - accuracy: 0.5125 - val_loss: 0.8586 - val_accuracy: 0.4242\n",
            "Epoch 168/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3134 - accuracy: 0.5047 - val_loss: 0.8909 - val_accuracy: 0.4266\n",
            "Epoch 169/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3059 - accuracy: 0.5031 - val_loss: 0.8632 - val_accuracy: 0.4232\n",
            "Epoch 170/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2770 - accuracy: 0.5103 - val_loss: 0.8652 - val_accuracy: 0.4213\n",
            "Epoch 171/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2848 - accuracy: 0.5088 - val_loss: 0.8930 - val_accuracy: 0.4220\n",
            "Epoch 172/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2838 - accuracy: 0.5091 - val_loss: 0.8803 - val_accuracy: 0.4213\n",
            "Epoch 173/511\n",
            "67/67 [==============================] - 2s 34ms/step - loss: 0.2797 - accuracy: 0.5082 - val_loss: 0.8599 - val_accuracy: 0.4237\n",
            "Epoch 174/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2691 - accuracy: 0.5141 - val_loss: 0.8875 - val_accuracy: 0.4198\n",
            "Epoch 175/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2681 - accuracy: 0.5117 - val_loss: 0.8569 - val_accuracy: 0.4179\n",
            "Epoch 176/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2736 - accuracy: 0.5110 - val_loss: 0.8667 - val_accuracy: 0.4225\n",
            "Epoch 177/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2747 - accuracy: 0.5124 - val_loss: 0.8583 - val_accuracy: 0.4193\n",
            "Epoch 178/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2731 - accuracy: 0.5121 - val_loss: 0.8584 - val_accuracy: 0.4251\n",
            "Epoch 179/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2883 - accuracy: 0.5111 - val_loss: 0.8641 - val_accuracy: 0.4234\n",
            "Epoch 180/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2723 - accuracy: 0.5107 - val_loss: 0.8712 - val_accuracy: 0.4193\n",
            "Epoch 181/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2681 - accuracy: 0.5121 - val_loss: 0.8683 - val_accuracy: 0.4215\n",
            "Epoch 182/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2793 - accuracy: 0.5124 - val_loss: 0.8509 - val_accuracy: 0.4213\n",
            "Epoch 183/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2832 - accuracy: 0.5077 - val_loss: 0.8578 - val_accuracy: 0.4254\n",
            "Epoch 184/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2762 - accuracy: 0.5095 - val_loss: 0.8651 - val_accuracy: 0.4201\n",
            "Epoch 185/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2813 - accuracy: 0.5109 - val_loss: 0.8710 - val_accuracy: 0.4266\n",
            "Epoch 186/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2903 - accuracy: 0.5075 - val_loss: 0.8879 - val_accuracy: 0.4184\n",
            "Epoch 187/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2840 - accuracy: 0.5082 - val_loss: 0.8811 - val_accuracy: 0.4220\n",
            "Epoch 188/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2767 - accuracy: 0.5122 - val_loss: 0.8665 - val_accuracy: 0.4290\n",
            "Epoch 189/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3115 - accuracy: 0.5063 - val_loss: 0.8752 - val_accuracy: 0.4234\n",
            "Epoch 190/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2774 - accuracy: 0.5097 - val_loss: 0.9083 - val_accuracy: 0.4256\n",
            "Epoch 191/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.3037 - accuracy: 0.5068 - val_loss: 0.8862 - val_accuracy: 0.4227\n",
            "Epoch 192/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2648 - accuracy: 0.5142 - val_loss: 0.8540 - val_accuracy: 0.4215\n",
            "Epoch 193/511\n",
            "67/67 [==============================] - 2s 30ms/step - loss: 0.3858 - accuracy: 0.4892 - val_loss: 0.8375 - val_accuracy: 0.4251\n",
            "Epoch 194/511\n",
            "67/67 [==============================] - 3s 46ms/step - loss: 0.2891 - accuracy: 0.5074 - val_loss: 0.8468 - val_accuracy: 0.4234\n",
            "Epoch 195/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2808 - accuracy: 0.5098 - val_loss: 0.8846 - val_accuracy: 0.4230\n",
            "Epoch 196/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2715 - accuracy: 0.5123 - val_loss: 0.8683 - val_accuracy: 0.4244\n",
            "Epoch 197/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2800 - accuracy: 0.5093 - val_loss: 0.8602 - val_accuracy: 0.4283\n",
            "Epoch 198/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2921 - accuracy: 0.5088 - val_loss: 0.8992 - val_accuracy: 0.4198\n",
            "Epoch 199/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2729 - accuracy: 0.5112 - val_loss: 0.8681 - val_accuracy: 0.4203\n",
            "Epoch 200/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2654 - accuracy: 0.5139 - val_loss: 0.8818 - val_accuracy: 0.4244\n",
            "Epoch 201/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2676 - accuracy: 0.5128 - val_loss: 0.8526 - val_accuracy: 0.4222\n",
            "Epoch 202/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2829 - accuracy: 0.5096 - val_loss: 0.8779 - val_accuracy: 0.4218\n",
            "Epoch 203/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2696 - accuracy: 0.5094 - val_loss: 0.8951 - val_accuracy: 0.4239\n",
            "Epoch 204/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2873 - accuracy: 0.5083 - val_loss: 0.8882 - val_accuracy: 0.4242\n",
            "Epoch 205/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2627 - accuracy: 0.5140 - val_loss: 0.8885 - val_accuracy: 0.4205\n",
            "Epoch 206/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2784 - accuracy: 0.5099 - val_loss: 0.8739 - val_accuracy: 0.4230\n",
            "Epoch 207/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2696 - accuracy: 0.5133 - val_loss: 0.9035 - val_accuracy: 0.4254\n",
            "Epoch 208/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2654 - accuracy: 0.5167 - val_loss: 0.8725 - val_accuracy: 0.4230\n",
            "Epoch 209/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2590 - accuracy: 0.5161 - val_loss: 0.8753 - val_accuracy: 0.4249\n",
            "Epoch 210/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2672 - accuracy: 0.5142 - val_loss: 0.8651 - val_accuracy: 0.4218\n",
            "Epoch 211/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2635 - accuracy: 0.5141 - val_loss: 0.8683 - val_accuracy: 0.4188\n",
            "Epoch 212/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2611 - accuracy: 0.5168 - val_loss: 0.8787 - val_accuracy: 0.4234\n",
            "Epoch 213/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2590 - accuracy: 0.5151 - val_loss: 0.8582 - val_accuracy: 0.4198\n",
            "Epoch 214/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3496 - accuracy: 0.5011 - val_loss: 0.8543 - val_accuracy: 0.4208\n",
            "Epoch 215/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2905 - accuracy: 0.5067 - val_loss: 0.8473 - val_accuracy: 0.4208\n",
            "Epoch 216/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2813 - accuracy: 0.5103 - val_loss: 0.8514 - val_accuracy: 0.4222\n",
            "Epoch 217/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2915 - accuracy: 0.5057 - val_loss: 0.8705 - val_accuracy: 0.4242\n",
            "Epoch 218/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2624 - accuracy: 0.5148 - val_loss: 0.8726 - val_accuracy: 0.4201\n",
            "Epoch 219/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2656 - accuracy: 0.5109 - val_loss: 0.8968 - val_accuracy: 0.4203\n",
            "Epoch 220/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2677 - accuracy: 0.5132 - val_loss: 0.8606 - val_accuracy: 0.4213\n",
            "Epoch 221/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2714 - accuracy: 0.5116 - val_loss: 0.8905 - val_accuracy: 0.4184\n",
            "Epoch 222/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2766 - accuracy: 0.5138 - val_loss: 0.8682 - val_accuracy: 0.4128\n",
            "Epoch 223/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3014 - accuracy: 0.5045 - val_loss: 0.8491 - val_accuracy: 0.4186\n",
            "Epoch 224/511\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 0.2709 - accuracy: 0.5107 - val_loss: 0.8540 - val_accuracy: 0.4205\n",
            "Epoch 225/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2676 - accuracy: 0.5123 - val_loss: 0.8978 - val_accuracy: 0.4225\n",
            "Epoch 226/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2559 - accuracy: 0.5160 - val_loss: 0.8734 - val_accuracy: 0.4196\n",
            "Epoch 227/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2929 - accuracy: 0.5128 - val_loss: 0.8581 - val_accuracy: 0.4181\n",
            "Epoch 228/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.4763 - accuracy: 0.4712 - val_loss: 0.8335 - val_accuracy: 0.4191\n",
            "Epoch 229/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.3595 - accuracy: 0.4853 - val_loss: 0.8472 - val_accuracy: 0.4278\n",
            "Epoch 230/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.3010 - accuracy: 0.5016 - val_loss: 0.8608 - val_accuracy: 0.4254\n",
            "Epoch 231/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2803 - accuracy: 0.5088 - val_loss: 0.8568 - val_accuracy: 0.4285\n",
            "Epoch 232/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2571 - accuracy: 0.5151 - val_loss: 0.8822 - val_accuracy: 0.4225\n",
            "Epoch 233/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2716 - accuracy: 0.5121 - val_loss: 0.8458 - val_accuracy: 0.4232\n",
            "Epoch 234/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2743 - accuracy: 0.5137 - val_loss: 0.9050 - val_accuracy: 0.4225\n",
            "Epoch 235/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2584 - accuracy: 0.5157 - val_loss: 0.8833 - val_accuracy: 0.4244\n",
            "Epoch 236/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2583 - accuracy: 0.5154 - val_loss: 0.9000 - val_accuracy: 0.4222\n",
            "Epoch 237/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2534 - accuracy: 0.5176 - val_loss: 0.8902 - val_accuracy: 0.4208\n",
            "Epoch 238/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2517 - accuracy: 0.5164 - val_loss: 0.8792 - val_accuracy: 0.4247\n",
            "Epoch 239/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2433 - accuracy: 0.5184 - val_loss: 0.8745 - val_accuracy: 0.4201\n",
            "Epoch 240/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2830 - accuracy: 0.5120 - val_loss: 0.8562 - val_accuracy: 0.4176\n",
            "Epoch 241/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2786 - accuracy: 0.5095 - val_loss: 0.9034 - val_accuracy: 0.4191\n",
            "Epoch 242/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2516 - accuracy: 0.5158 - val_loss: 0.9052 - val_accuracy: 0.4239\n",
            "Epoch 243/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2566 - accuracy: 0.5177 - val_loss: 0.8607 - val_accuracy: 0.4150\n",
            "Epoch 244/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2653 - accuracy: 0.5153 - val_loss: 0.8731 - val_accuracy: 0.4213\n",
            "Epoch 245/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2438 - accuracy: 0.5188 - val_loss: 0.9145 - val_accuracy: 0.4205\n",
            "Epoch 246/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2619 - accuracy: 0.5156 - val_loss: 0.8808 - val_accuracy: 0.4220\n",
            "Epoch 247/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2743 - accuracy: 0.5113 - val_loss: 0.8848 - val_accuracy: 0.4188\n",
            "Epoch 248/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2601 - accuracy: 0.5162 - val_loss: 0.8884 - val_accuracy: 0.4162\n",
            "Epoch 249/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2671 - accuracy: 0.5118 - val_loss: 0.9036 - val_accuracy: 0.4242\n",
            "Epoch 250/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2753 - accuracy: 0.5116 - val_loss: 0.8941 - val_accuracy: 0.4230\n",
            "Epoch 251/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2836 - accuracy: 0.5120 - val_loss: 0.8662 - val_accuracy: 0.4232\n",
            "Epoch 252/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2578 - accuracy: 0.5163 - val_loss: 0.8699 - val_accuracy: 0.4210\n",
            "Epoch 253/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2558 - accuracy: 0.5158 - val_loss: 0.8621 - val_accuracy: 0.4225\n",
            "Epoch 254/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2646 - accuracy: 0.5150 - val_loss: 0.8819 - val_accuracy: 0.4201\n",
            "Epoch 255/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2482 - accuracy: 0.5156 - val_loss: 0.8854 - val_accuracy: 0.4210\n",
            "Epoch 256/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2528 - accuracy: 0.5168 - val_loss: 0.9002 - val_accuracy: 0.4266\n",
            "Epoch 257/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2630 - accuracy: 0.5127 - val_loss: 0.9051 - val_accuracy: 0.4186\n",
            "Epoch 258/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2556 - accuracy: 0.5172 - val_loss: 0.8721 - val_accuracy: 0.4186\n",
            "Epoch 259/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2530 - accuracy: 0.5175 - val_loss: 0.8972 - val_accuracy: 0.4203\n",
            "Epoch 260/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2426 - accuracy: 0.5199 - val_loss: 0.8991 - val_accuracy: 0.4261\n",
            "Epoch 261/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2516 - accuracy: 0.5182 - val_loss: 0.9012 - val_accuracy: 0.4222\n",
            "Epoch 262/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2663 - accuracy: 0.5137 - val_loss: 0.8575 - val_accuracy: 0.4230\n",
            "Epoch 263/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2653 - accuracy: 0.5138 - val_loss: 0.9007 - val_accuracy: 0.4276\n",
            "Epoch 264/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2491 - accuracy: 0.5167 - val_loss: 0.8918 - val_accuracy: 0.4234\n",
            "Epoch 265/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2595 - accuracy: 0.5164 - val_loss: 0.8895 - val_accuracy: 0.4225\n",
            "Epoch 266/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2409 - accuracy: 0.5198 - val_loss: 0.9109 - val_accuracy: 0.4264\n",
            "Epoch 267/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2452 - accuracy: 0.5181 - val_loss: 0.8864 - val_accuracy: 0.4203\n",
            "Epoch 268/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2417 - accuracy: 0.5200 - val_loss: 0.9026 - val_accuracy: 0.4237\n",
            "Epoch 269/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2591 - accuracy: 0.5164 - val_loss: 0.8906 - val_accuracy: 0.4188\n",
            "Epoch 270/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2653 - accuracy: 0.5146 - val_loss: 0.8857 - val_accuracy: 0.4201\n",
            "Epoch 271/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2559 - accuracy: 0.5152 - val_loss: 0.8801 - val_accuracy: 0.4208\n",
            "Epoch 272/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2542 - accuracy: 0.5151 - val_loss: 0.8970 - val_accuracy: 0.4196\n",
            "Epoch 273/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2435 - accuracy: 0.5193 - val_loss: 0.8906 - val_accuracy: 0.4225\n",
            "Epoch 274/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2427 - accuracy: 0.5178 - val_loss: 0.9087 - val_accuracy: 0.4244\n",
            "Epoch 275/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2831 - accuracy: 0.5101 - val_loss: 0.8758 - val_accuracy: 0.4234\n",
            "Epoch 276/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2874 - accuracy: 0.5075 - val_loss: 0.8620 - val_accuracy: 0.4184\n",
            "Epoch 277/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2708 - accuracy: 0.5111 - val_loss: 0.8898 - val_accuracy: 0.4157\n",
            "Epoch 278/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2490 - accuracy: 0.5159 - val_loss: 0.8780 - val_accuracy: 0.4184\n",
            "Epoch 279/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2692 - accuracy: 0.5115 - val_loss: 0.8849 - val_accuracy: 0.4232\n",
            "Epoch 280/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2758 - accuracy: 0.5093 - val_loss: 0.8934 - val_accuracy: 0.4218\n",
            "Epoch 281/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2689 - accuracy: 0.5121 - val_loss: 0.8668 - val_accuracy: 0.4215\n",
            "Epoch 282/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2636 - accuracy: 0.5130 - val_loss: 0.8794 - val_accuracy: 0.4186\n",
            "Epoch 283/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2868 - accuracy: 0.5072 - val_loss: 0.9234 - val_accuracy: 0.4256\n",
            "Epoch 284/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2515 - accuracy: 0.5161 - val_loss: 0.8963 - val_accuracy: 0.4198\n",
            "Epoch 285/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2578 - accuracy: 0.5153 - val_loss: 0.9001 - val_accuracy: 0.4208\n",
            "Epoch 286/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2397 - accuracy: 0.5200 - val_loss: 0.9126 - val_accuracy: 0.4205\n",
            "Epoch 287/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2577 - accuracy: 0.5179 - val_loss: 0.9064 - val_accuracy: 0.4239\n",
            "Epoch 288/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2617 - accuracy: 0.5164 - val_loss: 0.8918 - val_accuracy: 0.4220\n",
            "Epoch 289/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2374 - accuracy: 0.5206 - val_loss: 0.8977 - val_accuracy: 0.4220\n",
            "Epoch 290/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2593 - accuracy: 0.5139 - val_loss: 0.8947 - val_accuracy: 0.4203\n",
            "Epoch 291/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2366 - accuracy: 0.5204 - val_loss: 0.8893 - val_accuracy: 0.4218\n",
            "Epoch 292/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2333 - accuracy: 0.5217 - val_loss: 0.8849 - val_accuracy: 0.4210\n",
            "Epoch 293/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2479 - accuracy: 0.5180 - val_loss: 0.9162 - val_accuracy: 0.4191\n",
            "Epoch 294/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2487 - accuracy: 0.5196 - val_loss: 0.9160 - val_accuracy: 0.4230\n",
            "Epoch 295/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2444 - accuracy: 0.5191 - val_loss: 0.9045 - val_accuracy: 0.4215\n",
            "Epoch 296/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2412 - accuracy: 0.5197 - val_loss: 0.9054 - val_accuracy: 0.4198\n",
            "Epoch 297/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2383 - accuracy: 0.5211 - val_loss: 0.8940 - val_accuracy: 0.4220\n",
            "Epoch 298/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2524 - accuracy: 0.5164 - val_loss: 0.8712 - val_accuracy: 0.4174\n",
            "Epoch 299/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2506 - accuracy: 0.5166 - val_loss: 0.8863 - val_accuracy: 0.4220\n",
            "Epoch 300/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2504 - accuracy: 0.5157 - val_loss: 0.8922 - val_accuracy: 0.4210\n",
            "Epoch 301/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2552 - accuracy: 0.5167 - val_loss: 0.8995 - val_accuracy: 0.4215\n",
            "Epoch 302/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2355 - accuracy: 0.5206 - val_loss: 0.9462 - val_accuracy: 0.4230\n",
            "Epoch 303/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2408 - accuracy: 0.5185 - val_loss: 0.8970 - val_accuracy: 0.4232\n",
            "Epoch 304/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2484 - accuracy: 0.5174 - val_loss: 0.9119 - val_accuracy: 0.4193\n",
            "Epoch 305/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2410 - accuracy: 0.5186 - val_loss: 0.9210 - val_accuracy: 0.4205\n",
            "Epoch 306/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2459 - accuracy: 0.5173 - val_loss: 0.9115 - val_accuracy: 0.4181\n",
            "Epoch 307/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2624 - accuracy: 0.5127 - val_loss: 0.9183 - val_accuracy: 0.4186\n",
            "Epoch 308/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2652 - accuracy: 0.5157 - val_loss: 0.9095 - val_accuracy: 0.4230\n",
            "Epoch 309/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2385 - accuracy: 0.5190 - val_loss: 0.8932 - val_accuracy: 0.4191\n",
            "Epoch 310/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2402 - accuracy: 0.5200 - val_loss: 0.9083 - val_accuracy: 0.4213\n",
            "Epoch 311/511\n",
            "67/67 [==============================] - 4s 58ms/step - loss: 0.2536 - accuracy: 0.5133 - val_loss: 0.8716 - val_accuracy: 0.4232\n",
            "Epoch 312/511\n",
            "67/67 [==============================] - 3s 48ms/step - loss: 0.2973 - accuracy: 0.5085 - val_loss: 0.8757 - val_accuracy: 0.4232\n",
            "Epoch 313/511\n",
            "67/67 [==============================] - 4s 62ms/step - loss: 0.2562 - accuracy: 0.5184 - val_loss: 0.9180 - val_accuracy: 0.4208\n",
            "Epoch 314/511\n",
            "67/67 [==============================] - 4s 60ms/step - loss: 0.2405 - accuracy: 0.5191 - val_loss: 0.9014 - val_accuracy: 0.4215\n",
            "Epoch 315/511\n",
            "67/67 [==============================] - 3s 47ms/step - loss: 0.2289 - accuracy: 0.5213 - val_loss: 0.8949 - val_accuracy: 0.4201\n",
            "Epoch 316/511\n",
            "67/67 [==============================] - 3s 47ms/step - loss: 0.2379 - accuracy: 0.5207 - val_loss: 0.9314 - val_accuracy: 0.4222\n",
            "Epoch 317/511\n",
            "67/67 [==============================] - 3s 49ms/step - loss: 0.2461 - accuracy: 0.5164 - val_loss: 0.9059 - val_accuracy: 0.4225\n",
            "Epoch 318/511\n",
            "67/67 [==============================] - 3s 50ms/step - loss: 0.2771 - accuracy: 0.5129 - val_loss: 0.8994 - val_accuracy: 0.4181\n",
            "Epoch 319/511\n",
            "67/67 [==============================] - 3s 39ms/step - loss: 0.2568 - accuracy: 0.5179 - val_loss: 0.8900 - val_accuracy: 0.4162\n",
            "Epoch 320/511\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 0.2429 - accuracy: 0.5200 - val_loss: 0.8893 - val_accuracy: 0.4230\n",
            "Epoch 321/511\n",
            "67/67 [==============================] - 3s 42ms/step - loss: 0.2402 - accuracy: 0.5187 - val_loss: 0.8890 - val_accuracy: 0.4196\n",
            "Epoch 322/511\n",
            "67/67 [==============================] - 3s 43ms/step - loss: 0.2860 - accuracy: 0.5080 - val_loss: 0.8987 - val_accuracy: 0.4150\n",
            "Epoch 323/511\n",
            "67/67 [==============================] - 3s 50ms/step - loss: 0.2491 - accuracy: 0.5147 - val_loss: 0.9002 - val_accuracy: 0.4220\n",
            "Epoch 324/511\n",
            "67/67 [==============================] - 3s 46ms/step - loss: 0.2358 - accuracy: 0.5205 - val_loss: 0.9001 - val_accuracy: 0.4176\n",
            "Epoch 325/511\n",
            "67/67 [==============================] - 2s 33ms/step - loss: 0.2400 - accuracy: 0.5194 - val_loss: 0.9110 - val_accuracy: 0.4205\n",
            "Epoch 326/511\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 0.2275 - accuracy: 0.5247 - val_loss: 0.8993 - val_accuracy: 0.4244\n",
            "Epoch 327/511\n",
            "67/67 [==============================] - 4s 59ms/step - loss: 0.2533 - accuracy: 0.5145 - val_loss: 0.9007 - val_accuracy: 0.4198\n",
            "Epoch 328/511\n",
            "67/67 [==============================] - 4s 54ms/step - loss: 0.2523 - accuracy: 0.5179 - val_loss: 0.8881 - val_accuracy: 0.4184\n",
            "Epoch 329/511\n",
            "67/67 [==============================] - 2s 34ms/step - loss: 0.2636 - accuracy: 0.5178 - val_loss: 0.9126 - val_accuracy: 0.4196\n",
            "Epoch 330/511\n",
            "67/67 [==============================] - 3s 45ms/step - loss: 0.2595 - accuracy: 0.5130 - val_loss: 0.8951 - val_accuracy: 0.4184\n",
            "Epoch 331/511\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 0.2433 - accuracy: 0.5176 - val_loss: 0.9271 - val_accuracy: 0.4218\n",
            "Epoch 332/511\n",
            "67/67 [==============================] - 3s 46ms/step - loss: 0.2463 - accuracy: 0.5172 - val_loss: 0.8895 - val_accuracy: 0.4220\n",
            "Epoch 333/511\n",
            "67/67 [==============================] - 2s 35ms/step - loss: 0.2372 - accuracy: 0.5209 - val_loss: 0.8842 - val_accuracy: 0.4215\n",
            "Epoch 334/511\n",
            "67/67 [==============================] - 2s 33ms/step - loss: 0.2437 - accuracy: 0.5215 - val_loss: 0.9154 - val_accuracy: 0.4181\n",
            "Epoch 335/511\n",
            "67/67 [==============================] - 3s 42ms/step - loss: 0.2872 - accuracy: 0.5099 - val_loss: 0.8924 - val_accuracy: 0.4225\n",
            "Epoch 336/511\n",
            "67/67 [==============================] - 3s 39ms/step - loss: 0.2718 - accuracy: 0.5139 - val_loss: 0.9091 - val_accuracy: 0.4191\n",
            "Epoch 337/511\n",
            "67/67 [==============================] - 3s 42ms/step - loss: 0.2335 - accuracy: 0.5224 - val_loss: 0.8859 - val_accuracy: 0.4215\n",
            "Epoch 338/511\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 0.2337 - accuracy: 0.5186 - val_loss: 0.8879 - val_accuracy: 0.4184\n",
            "Epoch 339/511\n",
            "67/67 [==============================] - 3s 45ms/step - loss: 0.2371 - accuracy: 0.5201 - val_loss: 0.9138 - val_accuracy: 0.4215\n",
            "Epoch 340/511\n",
            "67/67 [==============================] - 2s 36ms/step - loss: 0.2258 - accuracy: 0.5235 - val_loss: 0.9145 - val_accuracy: 0.4215\n",
            "Epoch 341/511\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 0.2574 - accuracy: 0.5154 - val_loss: 0.9023 - val_accuracy: 0.4188\n",
            "Epoch 342/511\n",
            "67/67 [==============================] - 3s 43ms/step - loss: 0.2690 - accuracy: 0.5130 - val_loss: 0.9114 - val_accuracy: 0.4210\n",
            "Epoch 343/511\n",
            "67/67 [==============================] - 2s 33ms/step - loss: 0.2358 - accuracy: 0.5197 - val_loss: 0.8999 - val_accuracy: 0.4201\n",
            "Epoch 344/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2313 - accuracy: 0.5203 - val_loss: 0.9273 - val_accuracy: 0.4193\n",
            "Epoch 345/511\n",
            "67/67 [==============================] - 3s 39ms/step - loss: 0.2451 - accuracy: 0.5185 - val_loss: 0.9151 - val_accuracy: 0.4198\n",
            "Epoch 346/511\n",
            "67/67 [==============================] - 3s 46ms/step - loss: 0.2420 - accuracy: 0.5180 - val_loss: 0.8975 - val_accuracy: 0.4169\n",
            "Epoch 347/511\n",
            "67/67 [==============================] - 2s 30ms/step - loss: 0.2608 - accuracy: 0.5136 - val_loss: 0.9257 - val_accuracy: 0.4225\n",
            "Epoch 348/511\n",
            "67/67 [==============================] - 3s 43ms/step - loss: 0.2321 - accuracy: 0.5216 - val_loss: 0.9073 - val_accuracy: 0.4213\n",
            "Epoch 349/511\n",
            "67/67 [==============================] - 2s 33ms/step - loss: 0.2395 - accuracy: 0.5194 - val_loss: 0.9003 - val_accuracy: 0.4239\n",
            "Epoch 350/511\n",
            "67/67 [==============================] - 3s 45ms/step - loss: 0.2302 - accuracy: 0.5207 - val_loss: 0.9116 - val_accuracy: 0.4213\n",
            "Epoch 351/511\n",
            "67/67 [==============================] - 2s 32ms/step - loss: 0.2261 - accuracy: 0.5225 - val_loss: 0.9137 - val_accuracy: 0.4242\n",
            "Epoch 352/511\n",
            "67/67 [==============================] - 2s 34ms/step - loss: 0.2378 - accuracy: 0.5193 - val_loss: 0.9127 - val_accuracy: 0.4208\n",
            "Epoch 353/511\n",
            "67/67 [==============================] - 2s 35ms/step - loss: 0.2296 - accuracy: 0.5210 - val_loss: 0.9040 - val_accuracy: 0.4213\n",
            "Epoch 354/511\n",
            "67/67 [==============================] - 2s 32ms/step - loss: 0.2442 - accuracy: 0.5167 - val_loss: 0.9117 - val_accuracy: 0.4268\n",
            "Epoch 355/511\n",
            "67/67 [==============================] - 3s 41ms/step - loss: 0.2503 - accuracy: 0.5173 - val_loss: 0.9329 - val_accuracy: 0.4230\n",
            "Epoch 356/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2328 - accuracy: 0.5210 - val_loss: 0.9165 - val_accuracy: 0.4179\n",
            "Epoch 357/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2483 - accuracy: 0.5199 - val_loss: 0.9278 - val_accuracy: 0.4191\n",
            "Epoch 358/511\n",
            "67/67 [==============================] - 2s 32ms/step - loss: 0.2465 - accuracy: 0.5194 - val_loss: 0.9307 - val_accuracy: 0.4234\n",
            "Epoch 359/511\n",
            "67/67 [==============================] - 2s 36ms/step - loss: 0.3588 - accuracy: 0.4932 - val_loss: 0.9259 - val_accuracy: 0.4213\n",
            "Epoch 360/511\n",
            "67/67 [==============================] - 2s 34ms/step - loss: 0.2852 - accuracy: 0.5066 - val_loss: 0.8804 - val_accuracy: 0.4155\n",
            "Epoch 361/511\n",
            "67/67 [==============================] - 3s 39ms/step - loss: 0.2508 - accuracy: 0.5144 - val_loss: 0.9135 - val_accuracy: 0.4186\n",
            "Epoch 362/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2376 - accuracy: 0.5157 - val_loss: 0.9230 - val_accuracy: 0.4210\n",
            "Epoch 363/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2274 - accuracy: 0.5224 - val_loss: 0.9120 - val_accuracy: 0.4164\n",
            "Epoch 364/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2403 - accuracy: 0.5191 - val_loss: 0.9114 - val_accuracy: 0.4201\n",
            "Epoch 365/511\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 0.2501 - accuracy: 0.5171 - val_loss: 0.8987 - val_accuracy: 0.4186\n",
            "Epoch 366/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2567 - accuracy: 0.5164 - val_loss: 0.9189 - val_accuracy: 0.4218\n",
            "Epoch 367/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2424 - accuracy: 0.5193 - val_loss: 0.9188 - val_accuracy: 0.4278\n",
            "Epoch 368/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2351 - accuracy: 0.5190 - val_loss: 0.9215 - val_accuracy: 0.4191\n",
            "Epoch 369/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2302 - accuracy: 0.5220 - val_loss: 0.9157 - val_accuracy: 0.4184\n",
            "Epoch 370/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2369 - accuracy: 0.5195 - val_loss: 0.9301 - val_accuracy: 0.4220\n",
            "Epoch 371/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2455 - accuracy: 0.5190 - val_loss: 0.9177 - val_accuracy: 0.4198\n",
            "Epoch 372/511\n",
            "67/67 [==============================] - 3s 41ms/step - loss: 0.2296 - accuracy: 0.5224 - val_loss: 0.8967 - val_accuracy: 0.4188\n",
            "Epoch 373/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2413 - accuracy: 0.5207 - val_loss: 0.9045 - val_accuracy: 0.4193\n",
            "Epoch 374/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2394 - accuracy: 0.5224 - val_loss: 0.9266 - val_accuracy: 0.4210\n",
            "Epoch 375/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2574 - accuracy: 0.5173 - val_loss: 0.8980 - val_accuracy: 0.4174\n",
            "Epoch 376/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2379 - accuracy: 0.5237 - val_loss: 0.9225 - val_accuracy: 0.4138\n",
            "Epoch 377/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2417 - accuracy: 0.5180 - val_loss: 0.9154 - val_accuracy: 0.4205\n",
            "Epoch 378/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2202 - accuracy: 0.5229 - val_loss: 0.9384 - val_accuracy: 0.4196\n",
            "Epoch 379/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2163 - accuracy: 0.5248 - val_loss: 0.9393 - val_accuracy: 0.4273\n",
            "Epoch 380/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2405 - accuracy: 0.5186 - val_loss: 0.9001 - val_accuracy: 0.4203\n",
            "Epoch 381/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2196 - accuracy: 0.5258 - val_loss: 0.9285 - val_accuracy: 0.4179\n",
            "Epoch 382/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2160 - accuracy: 0.5257 - val_loss: 0.9182 - val_accuracy: 0.4184\n",
            "Epoch 383/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2331 - accuracy: 0.5212 - val_loss: 0.9129 - val_accuracy: 0.4198\n",
            "Epoch 384/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2384 - accuracy: 0.5220 - val_loss: 0.9030 - val_accuracy: 0.4213\n",
            "Epoch 385/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2848 - accuracy: 0.5143 - val_loss: 0.9098 - val_accuracy: 0.4220\n",
            "Epoch 386/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2405 - accuracy: 0.5200 - val_loss: 0.9041 - val_accuracy: 0.4230\n",
            "Epoch 387/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2502 - accuracy: 0.5174 - val_loss: 0.8898 - val_accuracy: 0.4159\n",
            "Epoch 388/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2393 - accuracy: 0.5219 - val_loss: 0.8948 - val_accuracy: 0.4179\n",
            "Epoch 389/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2451 - accuracy: 0.5178 - val_loss: 0.8856 - val_accuracy: 0.4113\n",
            "Epoch 390/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2940 - accuracy: 0.5099 - val_loss: 0.9334 - val_accuracy: 0.4164\n",
            "Epoch 391/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2402 - accuracy: 0.5214 - val_loss: 0.9055 - val_accuracy: 0.4140\n",
            "Epoch 392/511\n",
            "67/67 [==============================] - 2s 36ms/step - loss: 0.2877 - accuracy: 0.5079 - val_loss: 0.8894 - val_accuracy: 0.4247\n",
            "Epoch 393/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2430 - accuracy: 0.5184 - val_loss: 0.8941 - val_accuracy: 0.4205\n",
            "Epoch 394/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2350 - accuracy: 0.5235 - val_loss: 0.8979 - val_accuracy: 0.4220\n",
            "Epoch 395/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2226 - accuracy: 0.5253 - val_loss: 0.9067 - val_accuracy: 0.4191\n",
            "Epoch 396/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2323 - accuracy: 0.5222 - val_loss: 0.9138 - val_accuracy: 0.4208\n",
            "Epoch 397/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2193 - accuracy: 0.5247 - val_loss: 0.8906 - val_accuracy: 0.4220\n",
            "Epoch 398/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2434 - accuracy: 0.5161 - val_loss: 0.9256 - val_accuracy: 0.4271\n",
            "Epoch 399/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2270 - accuracy: 0.5245 - val_loss: 0.9267 - val_accuracy: 0.4203\n",
            "Epoch 400/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2601 - accuracy: 0.5196 - val_loss: 0.9099 - val_accuracy: 0.4232\n",
            "Epoch 401/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2280 - accuracy: 0.5236 - val_loss: 0.9232 - val_accuracy: 0.4186\n",
            "Epoch 402/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2188 - accuracy: 0.5250 - val_loss: 0.9269 - val_accuracy: 0.4237\n",
            "Epoch 403/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2233 - accuracy: 0.5237 - val_loss: 0.9341 - val_accuracy: 0.4225\n",
            "Epoch 404/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2237 - accuracy: 0.5242 - val_loss: 0.9145 - val_accuracy: 0.4155\n",
            "Epoch 405/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2124 - accuracy: 0.5280 - val_loss: 0.9104 - val_accuracy: 0.4181\n",
            "Epoch 406/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2142 - accuracy: 0.5260 - val_loss: 0.9158 - val_accuracy: 0.4176\n",
            "Epoch 407/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2138 - accuracy: 0.5264 - val_loss: 0.8886 - val_accuracy: 0.4191\n",
            "Epoch 408/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2086 - accuracy: 0.5267 - val_loss: 0.9324 - val_accuracy: 0.4225\n",
            "Epoch 409/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2335 - accuracy: 0.5208 - val_loss: 0.9347 - val_accuracy: 0.4227\n",
            "Epoch 410/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2217 - accuracy: 0.5250 - val_loss: 0.9178 - val_accuracy: 0.4208\n",
            "Epoch 411/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2159 - accuracy: 0.5280 - val_loss: 0.8938 - val_accuracy: 0.4210\n",
            "Epoch 412/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2358 - accuracy: 0.5223 - val_loss: 0.9244 - val_accuracy: 0.4237\n",
            "Epoch 413/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2268 - accuracy: 0.5236 - val_loss: 0.9100 - val_accuracy: 0.4242\n",
            "Epoch 414/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2173 - accuracy: 0.5249 - val_loss: 0.9115 - val_accuracy: 0.4237\n",
            "Epoch 415/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2139 - accuracy: 0.5285 - val_loss: 0.9304 - val_accuracy: 0.4218\n",
            "Epoch 416/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2102 - accuracy: 0.5279 - val_loss: 0.9218 - val_accuracy: 0.4174\n",
            "Epoch 417/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2200 - accuracy: 0.5240 - val_loss: 0.9152 - val_accuracy: 0.4203\n",
            "Epoch 418/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2529 - accuracy: 0.5170 - val_loss: 0.9270 - val_accuracy: 0.4191\n",
            "Epoch 419/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.3574 - accuracy: 0.4951 - val_loss: 0.8883 - val_accuracy: 0.4242\n",
            "Epoch 420/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2644 - accuracy: 0.5152 - val_loss: 0.8764 - val_accuracy: 0.4213\n",
            "Epoch 421/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.3141 - accuracy: 0.5015 - val_loss: 0.8811 - val_accuracy: 0.4210\n",
            "Epoch 422/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2423 - accuracy: 0.5142 - val_loss: 0.9088 - val_accuracy: 0.4213\n",
            "Epoch 423/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2417 - accuracy: 0.5184 - val_loss: 0.9257 - val_accuracy: 0.4220\n",
            "Epoch 424/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2295 - accuracy: 0.5213 - val_loss: 0.9156 - val_accuracy: 0.4169\n",
            "Epoch 425/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2258 - accuracy: 0.5235 - val_loss: 0.9023 - val_accuracy: 0.4215\n",
            "Epoch 426/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2336 - accuracy: 0.5210 - val_loss: 0.9047 - val_accuracy: 0.4176\n",
            "Epoch 427/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2161 - accuracy: 0.5273 - val_loss: 0.8770 - val_accuracy: 0.4145\n",
            "Epoch 428/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.3744 - accuracy: 0.4956 - val_loss: 0.9030 - val_accuracy: 0.4201\n",
            "Epoch 429/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2428 - accuracy: 0.5190 - val_loss: 0.9124 - val_accuracy: 0.4208\n",
            "Epoch 430/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2369 - accuracy: 0.5226 - val_loss: 0.9268 - val_accuracy: 0.4237\n",
            "Epoch 431/511\n",
            "67/67 [==============================] - 3s 42ms/step - loss: 0.2518 - accuracy: 0.5177 - val_loss: 0.9198 - val_accuracy: 0.4181\n",
            "Epoch 432/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2447 - accuracy: 0.5214 - val_loss: 0.9138 - val_accuracy: 0.4205\n",
            "Epoch 433/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2281 - accuracy: 0.5222 - val_loss: 0.9129 - val_accuracy: 0.4237\n",
            "Epoch 434/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2351 - accuracy: 0.5214 - val_loss: 0.9076 - val_accuracy: 0.4201\n",
            "Epoch 435/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2537 - accuracy: 0.5175 - val_loss: 0.8910 - val_accuracy: 0.4201\n",
            "Epoch 436/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2280 - accuracy: 0.5240 - val_loss: 0.8964 - val_accuracy: 0.4184\n",
            "Epoch 437/511\n",
            "67/67 [==============================] - 3s 41ms/step - loss: 0.2445 - accuracy: 0.5182 - val_loss: 0.9018 - val_accuracy: 0.4191\n",
            "Epoch 438/511\n",
            "67/67 [==============================] - 2s 31ms/step - loss: 0.2105 - accuracy: 0.5288 - val_loss: 0.8983 - val_accuracy: 0.4225\n",
            "Epoch 439/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2343 - accuracy: 0.5212 - val_loss: 0.9314 - val_accuracy: 0.4239\n",
            "Epoch 440/511\n",
            "67/67 [==============================] - 3s 42ms/step - loss: 0.2323 - accuracy: 0.5225 - val_loss: 0.9350 - val_accuracy: 0.4188\n",
            "Epoch 441/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2171 - accuracy: 0.5255 - val_loss: 0.9381 - val_accuracy: 0.4210\n",
            "Epoch 442/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.3592 - accuracy: 0.4944 - val_loss: 0.9144 - val_accuracy: 0.4213\n",
            "Epoch 443/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2388 - accuracy: 0.5204 - val_loss: 0.9061 - val_accuracy: 0.4198\n",
            "Epoch 444/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2218 - accuracy: 0.5250 - val_loss: 0.9266 - val_accuracy: 0.4198\n",
            "Epoch 445/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2230 - accuracy: 0.5259 - val_loss: 0.9100 - val_accuracy: 0.4203\n",
            "Epoch 446/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2324 - accuracy: 0.5219 - val_loss: 0.9344 - val_accuracy: 0.4213\n",
            "Epoch 447/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2173 - accuracy: 0.5247 - val_loss: 0.9343 - val_accuracy: 0.4186\n",
            "Epoch 448/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2294 - accuracy: 0.5219 - val_loss: 0.8992 - val_accuracy: 0.4159\n",
            "Epoch 449/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2133 - accuracy: 0.5257 - val_loss: 0.9068 - val_accuracy: 0.4159\n",
            "Epoch 450/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2096 - accuracy: 0.5269 - val_loss: 0.8937 - val_accuracy: 0.4184\n",
            "Epoch 451/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.3403 - accuracy: 0.5023 - val_loss: 0.8852 - val_accuracy: 0.4213\n",
            "Epoch 452/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2243 - accuracy: 0.5232 - val_loss: 0.9150 - val_accuracy: 0.4167\n",
            "Epoch 453/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2104 - accuracy: 0.5262 - val_loss: 0.9129 - val_accuracy: 0.4191\n",
            "Epoch 454/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2242 - accuracy: 0.5259 - val_loss: 0.9489 - val_accuracy: 0.4193\n",
            "Epoch 455/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2081 - accuracy: 0.5283 - val_loss: 0.9134 - val_accuracy: 0.4186\n",
            "Epoch 456/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2180 - accuracy: 0.5279 - val_loss: 0.9263 - val_accuracy: 0.4225\n",
            "Epoch 457/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2074 - accuracy: 0.5273 - val_loss: 0.9117 - val_accuracy: 0.4150\n",
            "Epoch 458/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2377 - accuracy: 0.5179 - val_loss: 0.9398 - val_accuracy: 0.4208\n",
            "Epoch 459/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2549 - accuracy: 0.5193 - val_loss: 0.9079 - val_accuracy: 0.4150\n",
            "Epoch 460/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2194 - accuracy: 0.5266 - val_loss: 0.9068 - val_accuracy: 0.4198\n",
            "Epoch 461/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2199 - accuracy: 0.5258 - val_loss: 0.9065 - val_accuracy: 0.4188\n",
            "Epoch 462/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2070 - accuracy: 0.5275 - val_loss: 0.9205 - val_accuracy: 0.4201\n",
            "Epoch 463/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2076 - accuracy: 0.5288 - val_loss: 0.9478 - val_accuracy: 0.4232\n",
            "Epoch 464/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2120 - accuracy: 0.5263 - val_loss: 0.9297 - val_accuracy: 0.4244\n",
            "Epoch 465/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2228 - accuracy: 0.5249 - val_loss: 0.9152 - val_accuracy: 0.4205\n",
            "Epoch 466/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2122 - accuracy: 0.5259 - val_loss: 0.9233 - val_accuracy: 0.4176\n",
            "Epoch 467/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2246 - accuracy: 0.5225 - val_loss: 0.9289 - val_accuracy: 0.4198\n",
            "Epoch 468/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2158 - accuracy: 0.5252 - val_loss: 0.9462 - val_accuracy: 0.4232\n",
            "Epoch 469/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2195 - accuracy: 0.5211 - val_loss: 0.9241 - val_accuracy: 0.4179\n",
            "Epoch 470/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2170 - accuracy: 0.5271 - val_loss: 0.9386 - val_accuracy: 0.4172\n",
            "Epoch 471/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2064 - accuracy: 0.5293 - val_loss: 0.9475 - val_accuracy: 0.4188\n",
            "Epoch 472/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2020 - accuracy: 0.5276 - val_loss: 0.9258 - val_accuracy: 0.4184\n",
            "Epoch 473/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2173 - accuracy: 0.5262 - val_loss: 0.9617 - val_accuracy: 0.4193\n",
            "Epoch 474/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2340 - accuracy: 0.5220 - val_loss: 0.9388 - val_accuracy: 0.4208\n",
            "Epoch 475/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2403 - accuracy: 0.5167 - val_loss: 0.9227 - val_accuracy: 0.4179\n",
            "Epoch 476/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2180 - accuracy: 0.5242 - val_loss: 0.9208 - val_accuracy: 0.4218\n",
            "Epoch 477/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2022 - accuracy: 0.5290 - val_loss: 0.9304 - val_accuracy: 0.4150\n",
            "Epoch 478/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2240 - accuracy: 0.5223 - val_loss: 0.9306 - val_accuracy: 0.4169\n",
            "Epoch 479/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2107 - accuracy: 0.5277 - val_loss: 0.9547 - val_accuracy: 0.4222\n",
            "Epoch 480/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.2418 - accuracy: 0.5142 - val_loss: 0.9467 - val_accuracy: 0.4201\n",
            "Epoch 481/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2077 - accuracy: 0.5267 - val_loss: 0.9262 - val_accuracy: 0.4188\n",
            "Epoch 482/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2483 - accuracy: 0.5198 - val_loss: 0.9319 - val_accuracy: 0.4164\n",
            "Epoch 483/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2149 - accuracy: 0.5279 - val_loss: 0.9093 - val_accuracy: 0.4227\n",
            "Epoch 484/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2363 - accuracy: 0.5192 - val_loss: 0.9326 - val_accuracy: 0.4222\n",
            "Epoch 485/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2066 - accuracy: 0.5282 - val_loss: 0.9497 - val_accuracy: 0.4201\n",
            "Epoch 486/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2142 - accuracy: 0.5248 - val_loss: 0.8754 - val_accuracy: 0.4130\n",
            "Epoch 487/511\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 0.3349 - accuracy: 0.4976 - val_loss: 0.9106 - val_accuracy: 0.4225\n",
            "Epoch 488/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2217 - accuracy: 0.5236 - val_loss: 0.9136 - val_accuracy: 0.4164\n",
            "Epoch 489/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2144 - accuracy: 0.5265 - val_loss: 0.9143 - val_accuracy: 0.4205\n",
            "Epoch 490/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2102 - accuracy: 0.5269 - val_loss: 0.8977 - val_accuracy: 0.4186\n",
            "Epoch 491/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2178 - accuracy: 0.5266 - val_loss: 0.9426 - val_accuracy: 0.4167\n",
            "Epoch 492/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2324 - accuracy: 0.5226 - val_loss: 0.9163 - val_accuracy: 0.4222\n",
            "Epoch 493/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2044 - accuracy: 0.5290 - val_loss: 0.9269 - val_accuracy: 0.4164\n",
            "Epoch 494/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2037 - accuracy: 0.5291 - val_loss: 0.9364 - val_accuracy: 0.4208\n",
            "Epoch 495/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2040 - accuracy: 0.5276 - val_loss: 0.9376 - val_accuracy: 0.4198\n",
            "Epoch 496/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2160 - accuracy: 0.5247 - val_loss: 0.9064 - val_accuracy: 0.4215\n",
            "Epoch 497/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2221 - accuracy: 0.5252 - val_loss: 0.9552 - val_accuracy: 0.4271\n",
            "Epoch 498/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2521 - accuracy: 0.5210 - val_loss: 0.9354 - val_accuracy: 0.4174\n",
            "Epoch 499/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2188 - accuracy: 0.5255 - val_loss: 0.8824 - val_accuracy: 0.4142\n",
            "Epoch 500/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.3456 - accuracy: 0.4996 - val_loss: 0.8990 - val_accuracy: 0.4191\n",
            "Epoch 501/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2211 - accuracy: 0.5239 - val_loss: 0.9180 - val_accuracy: 0.4249\n",
            "Epoch 502/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2145 - accuracy: 0.5267 - val_loss: 0.9076 - val_accuracy: 0.4215\n",
            "Epoch 503/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2020 - accuracy: 0.5284 - val_loss: 0.9192 - val_accuracy: 0.4181\n",
            "Epoch 504/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2208 - accuracy: 0.5250 - val_loss: 0.9235 - val_accuracy: 0.4179\n",
            "Epoch 505/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2078 - accuracy: 0.5295 - val_loss: 0.9440 - val_accuracy: 0.4198\n",
            "Epoch 506/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2002 - accuracy: 0.5293 - val_loss: 0.9408 - val_accuracy: 0.4232\n",
            "Epoch 507/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2047 - accuracy: 0.5282 - val_loss: 0.9451 - val_accuracy: 0.4188\n",
            "Epoch 508/511\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 0.2120 - accuracy: 0.5219 - val_loss: 0.9160 - val_accuracy: 0.4174\n",
            "Epoch 509/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2234 - accuracy: 0.5257 - val_loss: 0.9378 - val_accuracy: 0.4215\n",
            "Epoch 510/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.2164 - accuracy: 0.5271 - val_loss: 0.9167 - val_accuracy: 0.4210\n",
            "Epoch 511/511\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 0.1988 - accuracy: 0.5286 - val_loss: 0.9330 - val_accuracy: 0.4157\n"
          ]
        }
      ],
      "source": [
        "#Acá su código\n",
        "\n",
        "#Aqui falto la data de validacion y son demasiadas pocas epocas, ademas que el batch_size se puede determinar automaticamente\n",
        "\n",
        "historial = red.fit(\n",
        "    X_train_n,\n",
        "    y_train,\n",
        "    epochs=511,\n",
        "    batch_size=250,\n",
        "    validation_data = (X_test_n , y_test)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = red.evaluate(X_train_n, y_train)\n",
        "print(\"\\n%s : %.2f%%\" %(red.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-dF8_keCYMk",
        "outputId": "2d239af8-299a-42c6-fafe-50b5e67347c3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "516/516 [==============================] - 2s 3ms/step - loss: 0.1819 - accuracy: 0.5336\n",
            "\n",
            "accuracy : 53.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE92z5eT0aEM"
      },
      "source": [
        "Evalue el modelo : muestre métricas de evaluación y gráficos para evaluar la pérdida y la precisión del entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3B80LnjNv8qi",
        "outputId": "97a9873c-90cc-406e-ea77-ff6f53342f29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(historial.history[\"accuracy\"])\n",
        "plt.plot(historial.history[\"val_accuracy\"])\n",
        "plt.plot(historial.history[\"loss\"])\n",
        "plt.plot(historial.history[\"val_loss\"])\n",
        "plt.title(\"model_accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"accuracy\",\"val_accuracy\",\"loss\",\"val_loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8pfwNu_0oHC"
      },
      "source": [
        "Realice alguna predicción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "X2mmZyiI0tgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa1e53e-e117-47bc-d2a2-1346ae3c154f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.predict of <keras.engine.sequential.Sequential object at 0x7f7f0e4b5250>>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#Acá su código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCmwJxDjY7Cz"
      },
      "source": [
        "# Conclusiones\n",
        "\n",
        "En esta sección debería aportar sus conclusiones\n",
        "\n",
        "Como conclusion pude evidenciar que se debe realizar un gran analisis respecto a los datos a analizar ya que en  un principio se hizo el preprocesamiento en base a lo que \"crei\" que seria necesario, dandome como resultado numeros muy erroneos y alejados de lo que esperaba, una vez realice un buen analisis y documente todos los errores que iba evidenciando pude llegar a un accuracy y un loss mejores de los que cuando empece.\n",
        "en base al dataset pude evidenciar que este tenia muchos outliers y estos interrumpian en la prediccion.\n",
        "\n",
        "como conclusion en base a mi trabajo pude evidenciar que es necesario realizar busquedas exhaustivas respecto a los datos a analizar y buscar modelos parecidos por ejemplo \"arquitecturas de redes neuronales para prediccion de precios\" las cuales me ayudaron a orientarme y a saber cuantas capas y neuronas poner, además de teoria sobre outliers, cuartiles y formulas para definir los limites inferior y superior.\n",
        "\n",
        "Sin más que agregar se agradece el desafio que propuso la evaluacion y el reto que propone además agradecer al docente ya que sin ella, no hubiera podido tener las ganas ni la fuerza para realizar la evaluacion."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}